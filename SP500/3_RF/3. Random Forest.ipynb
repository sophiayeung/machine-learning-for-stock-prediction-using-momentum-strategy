{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import datetime\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_auc_score, RocCurveDisplay\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using the m âˆˆ {{1,..20}, {40,60,...240}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_cum_process(df):\n",
    "    x = df.copy()\n",
    "    x = x.iloc[:,:240]\n",
    "    x[f'Cumulative_Return_40'] = x.iloc[:, 20:40].sum(axis=1)\n",
    "    x[f'Cumulative_Return_60'] = x.iloc[:, 40:60].sum(axis=1)\n",
    "    x[f'Cumulative_Return_80'] = x.iloc[:, 60:80].sum(axis=1)\n",
    "    x[f'Cumulative_Return_100'] = x.iloc[:, 80:100].sum(axis=1)\n",
    "    x[f'Cumulative_Return_120'] = x.iloc[:, 100:120].sum(axis=1)\n",
    "    x[f'Cumulative_Return_140'] = x.iloc[:, 120:140].sum(axis=1)\n",
    "    x[f'Cumulative_Return_160'] = x.iloc[:, 140:160].sum(axis=1)\n",
    "    x[f'Cumulative_Return_180'] = x.iloc[:, 160:180].sum(axis=1)\n",
    "    x[f'Cumulative_Return_200'] = x.iloc[:, 180:200].sum(axis=1)\n",
    "    x[f'Cumulative_Return_220'] = x.iloc[:, 200:220].sum(axis=1)\n",
    "    x[f'Cumulative_Return_240'] = x.iloc[:, 220:240].sum(axis=1)\n",
    "\n",
    "    x.drop(x.iloc[:,20:240], inplace=True,axis=1)\n",
    "    x.columns = x.columns.astype(str)\n",
    "    y = df.copy()\n",
    "    y = y.iloc[:,240:]\n",
    "    final = pd.concat([x,y],axis=1)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(245464, 31)\n",
      "(245464,)\n",
      "(120328, 31)\n",
      "(120328,)\n",
      "completed0\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training the model for Training Set 0 from 2024-03-26 12:24:32\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "{'n_estimators': [10, 100, 500, 1000], 'max_features': ['sqrt', 'log2'], 'max_depth': [3, 5, 7, 10, 50, None], 'criterion': ['gini', 'entropy'], 'bootstrap': [True, False]}\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/yeungwin/.conda/envs/tf/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1000, 'max_features': 'log2', 'max_depth': None, 'criterion': 'entropy', 'bootstrap': False}\n",
      "Model Saved\n",
      "Accuracy for round  0 :  0.5025762914699821\n",
      "Completed\n",
      "(245171, 31)\n",
      "(245171,)\n",
      "(120080, 31)\n",
      "(120080,)\n",
      "completed1\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training the model for Training Set 1 from 2024-03-26 13:03:25\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "{'n_estimators': [10, 100, 500, 1000], 'max_features': ['sqrt', 'log2'], 'max_depth': [3, 5, 7, 10, 50, None], 'criterion': ['gini', 'entropy'], 'bootstrap': [True, False]}\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/yeungwin/.conda/envs/tf/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1000, 'max_features': 'log2', 'max_depth': None, 'criterion': 'entropy', 'bootstrap': False}\n",
      "Model Saved\n",
      "Accuracy for round  1 :  0.5026315789473684\n",
      "Completed\n",
      "(245224, 31)\n",
      "(245224,)\n",
      "(120274, 31)\n",
      "(120274,)\n",
      "completed2\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training the model for Training Set 2 from 2024-03-26 13:46:16\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "{'n_estimators': [10, 100, 500, 1000], 'max_features': ['sqrt', 'log2'], 'max_depth': [3, 5, 7, 10, 50, None], 'criterion': ['gini', 'entropy'], 'bootstrap': [True, False]}\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/yeungwin/.conda/envs/tf/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1000, 'max_features': 'log2', 'max_depth': None, 'criterion': 'entropy', 'bootstrap': False}\n",
      "Model Saved\n",
      "Accuracy for round  2 :  0.5024693616242912\n",
      "Completed\n",
      "(245140, 31)\n",
      "(245140,)\n",
      "(119243, 31)\n",
      "(119243,)\n",
      "completed3\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training the model for Training Set 3 from 2024-03-26 14:26:25\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "{'n_estimators': [10, 100, 500, 1000], 'max_features': ['sqrt', 'log2'], 'max_depth': [3, 5, 7, 10, 50, None], 'criterion': ['gini', 'entropy'], 'bootstrap': [True, False]}\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/yeungwin/.conda/envs/tf/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1000, 'max_features': 'sqrt', 'max_depth': None, 'criterion': 'gini', 'bootstrap': False}\n",
      "Model Saved\n",
      "Accuracy for round  3 :  0.5005073673087729\n",
      "Completed\n",
      "(244381, 31)\n",
      "(244381,)\n",
      "(119325, 31)\n",
      "(119325,)\n",
      "completed4\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training the model for Training Set 4 from 2024-03-26 15:05:38\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "{'n_estimators': [10, 100, 500, 1000], 'max_features': ['sqrt', 'log2'], 'max_depth': [3, 5, 7, 10, 50, None], 'criterion': ['gini', 'entropy'], 'bootstrap': [True, False]}\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RDC/yeungwin/.conda/envs/tf/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1000, 'max_features': 'log2', 'max_depth': None, 'criterion': 'entropy', 'bootstrap': False}\n",
      "Model Saved\n",
      "Accuracy for round  4 :  0.500322648229625\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "features = 31\n",
    "#label = list(range(timesteps)) + ['target'] + ['ticker'] + ['target_date'] + ['sector']\n",
    "\n",
    "training_data = []\n",
    "training_label = []\n",
    "testing_data =[]\n",
    "testing_label =[]\n",
    "\n",
    "n_estimators = [10,100,500,1000]\n",
    "max_features = ['sqrt','log2']\n",
    "max_depth = [3,5,7,10,50]\n",
    "max_depth.append(None)\n",
    "bootstrap = [True, False]\n",
    "criterion = ['gini', 'entropy']\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    # read the data\n",
    "    path= '/SP500/data/'\n",
    "    train = pd.read_csv(path+'Set_' + str(i) + '_Train.csv', index_col=0).dropna()\n",
    "    train = df_cum_process(train)\n",
    "    test = pd.read_csv(path+'Set_' + str(i) + '_Test.csv', index_col=0).dropna()\n",
    "    test = df_cum_process(test)\n",
    "\n",
    "    #train.columns = label\n",
    "    #test.columns = label\n",
    "    x_train = train.iloc[:, :features]\n",
    "    y_train= train.iloc[:, features]\n",
    "    x_test = test.iloc[:, :features]\n",
    "    y_test = test.iloc[:,features]\n",
    "    \n",
    "    print(x_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(x_test.shape)\n",
    "    print(y_test.shape)\n",
    "    \n",
    "    print('completed'+str(i))\n",
    "    \n",
    "    print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "    print(\"Training the model for Training Set \" + str(i) + \" from \" +\n",
    "    datetime.datetime.strftime(datetime.datetime.now(), '%Y-%m-%d %H:%M:%S'))\n",
    "    print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "    # Create the random grids\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'criterion' :criterion,\n",
    "                   'bootstrap': bootstrap}\n",
    "    print(random_grid)        \n",
    "    rf = RandomForestClassifier(n_estimators = 10, n_jobs=-1,random_state =0)\n",
    "    rf_random = RandomizedSearchCV(rf, random_grid, n_iter=30, scoring='accuracy', n_jobs=-1, cv=3, \n",
    "                                   random_state =0, verbose =1, refit=True)\n",
    "    rf_random.fit(x_train,y_train)\n",
    "    print(rf_random.best_params_)\n",
    "    rf = rf_random.best_estimator_\n",
    "    y_pred = rf.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Model Saved\")\n",
    "    joblib.dump(rf, \"random_forest_\"+ str(i)+\".joblib\")\n",
    "        \n",
    "        \n",
    "    print(\"Accuracy for round \", i, \": \", accuracy)\n",
    "    #result\n",
    "    predict_prob = rf.predict_proba(x_test)\n",
    "    #pred = predict_prob.reshape((1, len(predict_prob))).tolist()[0]\n",
    "    pred = predict_prob[:,1] #only for class one\n",
    "    output_data = pd.DataFrame({'y_prob': pred, 'y_true': test['target'], 'Ticker': test['ticker'],\n",
    "                                    'Date': test['target_date'], 'Sector': test['sector'], })\n",
    "    pred_path = '/SP500/3_RF/rf_pred/'\n",
    "    output_data.to_csv(pred_path+'rf_pred_'+str(i)+'.csv')\n",
    "    print('Completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative_Return_240: 0.032826\n",
      "Cumulative_Return_180: 0.032576\n",
      "Cumulative_Return_160: 0.032424\n",
      "Cumulative_Return_140: 0.032403\n",
      "Cumulative_Return_200: 0.032377\n",
      "Cumulative_Return_220: 0.032365\n",
      "Normalized_Price_Return.13: 0.032331\n",
      "Normalized_Price_Return.18: 0.032307\n",
      "Normalized_Price_Return: 0.032286\n",
      "Normalized_Price_Return.11: 0.032280\n",
      "Cumulative_Return_100: 0.032266\n",
      "Normalized_Price_Return.4: 0.032264\n",
      "Normalized_Price_Return.17: 0.032263\n",
      "Cumulative_Return_120: 0.032258\n",
      "Normalized_Price_Return.3: 0.032231\n",
      "Normalized_Price_Return.10: 0.032207\n",
      "Normalized_Price_Return.2: 0.032203\n",
      "Normalized_Price_Return.5: 0.032198\n",
      "Normalized_Price_Return.9: 0.032187\n",
      "Normalized_Price_Return.1: 0.032184\n",
      "Normalized_Price_Return.19: 0.032177\n",
      "Normalized_Price_Return.7: 0.032164\n",
      "Normalized_Price_Return.6: 0.032162\n",
      "Normalized_Price_Return.14: 0.032151\n",
      "Normalized_Price_Return.15: 0.032142\n",
      "Cumulative_Return_60: 0.032139\n",
      "Normalized_Price_Return.8: 0.032137\n",
      "Cumulative_Return_40: 0.032136\n",
      "Normalized_Price_Return.16: 0.032129\n",
      "Normalized_Price_Return.12: 0.032121\n",
      "Cumulative_Return_80: 0.032105\n"
     ]
    }
   ],
   "source": [
    "# Get feature importances\n",
    "feature_importances = rf.feature_importances_\n",
    "\n",
    "# Map feature importances to column names\n",
    "column_names = x_train.columns \n",
    "feature_importance_dict = dict(zip(column_names, feature_importances))\n",
    "\n",
    "# Sort feature importances in descending order\n",
    "sorted_feature_importance = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print or plot feature importances\n",
    "for feature, importance in sorted_feature_importance:\n",
    "    print(f\"{feature}: {importance:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-tf]",
   "language": "python",
   "name": "conda-env-.conda-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
