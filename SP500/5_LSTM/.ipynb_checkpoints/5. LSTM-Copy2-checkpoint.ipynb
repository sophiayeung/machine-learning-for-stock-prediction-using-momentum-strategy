{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e6f9048",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-19 18:33:39.597689: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-19 18:33:39.935383: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-19 18:33:40.855788: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-19 18:33:40.855847: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-19 18:33:40.857099: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-19 18:33:41.316981: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-19 18:33:41.319247: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-19 18:33:45.154680: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, InputLayer, LSTM, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score\n",
    "import keras_tuner\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6820ddd8",
   "metadata": {},
   "source": [
    "# 240 days data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ea132a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyHyperModel(keras_tuner.HyperModel):\n",
    "    def build(self,hp):\n",
    "        model = Sequential()\n",
    "        model.add(InputLayer(input_shape=(240,1 )))\n",
    "        hp_units = hp.Choice('units', values=[32,64,128])\n",
    "        hp_lr = hp.Choice('learning_rate', values=[1e-6,1e-7,1e-8])\n",
    "        hp_regulariers = hp.Choice('regularies', values = ['l1','l2', 'None'])\n",
    "        if hp_regulariers == 'l1':\n",
    "            regularizers = keras.regularizers.L1(hp_lr)\n",
    "        elif hp_regulariers == 'l2':\n",
    "            regularizers = keras.regularizers.L2(hp_lr)\n",
    "        elif hp_regulariers == 'None':\n",
    "            regularizers = None\n",
    "        \n",
    "        model.add(LSTM(units=hp_units,kernel_regularizer=regularizers,name='dense_0'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        hp_optimizer = hp.Choice('optimizer', values=['sgd', 'rmsprop', 'adam',\"adamax\"])\n",
    "        if hp_optimizer == 'sgd':\n",
    "            optimizer = keras.optimizers.SGD(learning_rate=hp_lr)\n",
    "        elif hp_optimizer == 'rmsprop':\n",
    "            optimizer = keras.optimizers.RMSprop(learning_rate=hp_lr)\n",
    "        elif hp_optimizer == 'adam':\n",
    "            optimizer = keras.optimizers.Adam(learning_rate=hp_lr)\n",
    "        elif hp_optimizer == 'adamax':\n",
    "            optimizer = keras.optimizers.Adamax(learning_rate=hp_lr)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid optimizer choice\")\n",
    "\n",
    "        model.compile(\n",
    "            optimizer = optimizer\n",
    "            ,loss=keras.losses.BinaryCrossentropy()\n",
    "            , metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "\n",
    "    def fit(self, hp, model, *args, **kwargs):\n",
    "            return model.fit(\n",
    "                *args,\n",
    "                batch_size=hp.Choice(\"batch_size\", [16,32,64,128]),\n",
    "                **kwargs,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b77f37c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 24m 20s]\n",
      "val_accuracy: 0.503595232963562\n",
      "\n",
      "Best val_accuracy So Far: 0.512455940246582\n",
      "Total elapsed time: 31d 23h 00m 43s\n",
      "\n",
      "Search: Running Trial #11\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "128               |64                |units\n",
      "1e-06             |1e-06             |learning_rate\n",
      "l1                |l1                |regularies\n",
      "sgd               |adam              |optimizer\n",
      "128               |16                |batch_size\n",
      "\n",
      "Epoch 1/1000\n",
      "1535/1535 [==============================] - 544s 354ms/step - loss: 0.6934 - accuracy: 0.4992 - val_loss: 0.6932 - val_accuracy: 0.5014\n",
      "Epoch 2/1000\n",
      "1535/1535 [==============================] - 545s 355ms/step - loss: 0.6934 - accuracy: 0.4996 - val_loss: 0.6932 - val_accuracy: 0.5015\n",
      "Epoch 3/1000\n",
      "1535/1535 [==============================] - 545s 355ms/step - loss: 0.6934 - accuracy: 0.4988 - val_loss: 0.6932 - val_accuracy: 0.5016\n",
      "Epoch 4/1000\n",
      "1535/1535 [==============================] - 549s 358ms/step - loss: 0.6935 - accuracy: 0.4985 - val_loss: 0.6932 - val_accuracy: 0.5015\n",
      "Epoch 5/1000\n",
      "1535/1535 [==============================] - 545s 355ms/step - loss: 0.6935 - accuracy: 0.4983 - val_loss: 0.6932 - val_accuracy: 0.5015\n",
      "Epoch 6/1000\n",
      "1535/1535 [==============================] - 543s 353ms/step - loss: 0.6935 - accuracy: 0.4985 - val_loss: 0.6932 - val_accuracy: 0.5014\n",
      "Epoch 7/1000\n",
      "1535/1535 [==============================] - 555s 361ms/step - loss: 0.6935 - accuracy: 0.4988 - val_loss: 0.6932 - val_accuracy: 0.5015\n",
      "Epoch 8/1000\n",
      "1535/1535 [==============================] - 547s 356ms/step - loss: 0.6935 - accuracy: 0.4967 - val_loss: 0.6932 - val_accuracy: 0.5015\n",
      "Epoch 9/1000\n",
      "1535/1535 [==============================] - 538s 351ms/step - loss: 0.6935 - accuracy: 0.4967 - val_loss: 0.6932 - val_accuracy: 0.5016\n",
      "Epoch 10/1000\n",
      "1535/1535 [==============================] - 546s 356ms/step - loss: 0.6934 - accuracy: 0.4989 - val_loss: 0.6932 - val_accuracy: 0.5017\n",
      "Epoch 11/1000\n",
      "1535/1535 [==============================] - 547s 357ms/step - loss: 0.6934 - accuracy: 0.4985 - val_loss: 0.6932 - val_accuracy: 0.5015\n",
      "Epoch 12/1000\n",
      "1535/1535 [==============================] - 543s 354ms/step - loss: 0.6934 - accuracy: 0.4995 - val_loss: 0.6932 - val_accuracy: 0.5014\n",
      "Epoch 13/1000\n",
      "1535/1535 [==============================] - 550s 358ms/step - loss: 0.6935 - accuracy: 0.4988 - val_loss: 0.6932 - val_accuracy: 0.5014\n",
      "Epoch 14/1000\n",
      "1535/1535 [==============================] - 553s 360ms/step - loss: 0.6934 - accuracy: 0.5009 - val_loss: 0.6932 - val_accuracy: 0.5011\n",
      "Epoch 15/1000\n",
      "1535/1535 [==============================] - 549s 358ms/step - loss: 0.6934 - accuracy: 0.4986 - val_loss: 0.6932 - val_accuracy: 0.5013\n",
      "Epoch 16/1000\n",
      "1535/1535 [==============================] - 546s 356ms/step - loss: 0.6934 - accuracy: 0.4990 - val_loss: 0.6932 - val_accuracy: 0.5012\n",
      "Epoch 17/1000\n",
      "1535/1535 [==============================] - 543s 354ms/step - loss: 0.6935 - accuracy: 0.4994 - val_loss: 0.6932 - val_accuracy: 0.5012\n",
      "Epoch 18/1000\n",
      "1535/1535 [==============================] - 543s 354ms/step - loss: 0.6934 - accuracy: 0.4981 - val_loss: 0.6932 - val_accuracy: 0.5013\n",
      "Epoch 19/1000\n",
      "1535/1535 [==============================] - 547s 356ms/step - loss: 0.6934 - accuracy: 0.5002 - val_loss: 0.6932 - val_accuracy: 0.5013\n",
      "Epoch 20/1000\n",
      "1535/1535 [==============================] - 551s 359ms/step - loss: 0.6934 - accuracy: 0.4989 - val_loss: 0.6932 - val_accuracy: 0.5012\n",
      "Epoch 21/1000\n",
      "1535/1535 [==============================] - 546s 356ms/step - loss: 0.6935 - accuracy: 0.4988 - val_loss: 0.6932 - val_accuracy: 0.5011\n",
      "Epoch 22/1000\n",
      "1535/1535 [==============================] - 542s 353ms/step - loss: 0.6934 - accuracy: 0.4993 - val_loss: 0.6932 - val_accuracy: 0.5012\n",
      "Epoch 23/1000\n",
      "1535/1535 [==============================] - 544s 354ms/step - loss: 0.6934 - accuracy: 0.4989 - val_loss: 0.6932 - val_accuracy: 0.5012\n",
      "Epoch 24/1000\n",
      "1535/1535 [==============================] - 545s 355ms/step - loss: 0.6934 - accuracy: 0.4999 - val_loss: 0.6932 - val_accuracy: 0.5013\n",
      "Epoch 25/1000\n",
      "1535/1535 [==============================] - 544s 354ms/step - loss: 0.6934 - accuracy: 0.4993 - val_loss: 0.6932 - val_accuracy: 0.5013\n",
      "Epoch 26/1000\n",
      "1535/1535 [==============================] - 546s 355ms/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5012\n",
      "Epoch 27/1000\n",
      "1535/1535 [==============================] - 547s 356ms/step - loss: 0.6935 - accuracy: 0.4983 - val_loss: 0.6932 - val_accuracy: 0.5010\n",
      "Epoch 28/1000\n",
      "1535/1535 [==============================] - 547s 357ms/step - loss: 0.6934 - accuracy: 0.4996 - val_loss: 0.6932 - val_accuracy: 0.5011\n",
      "Epoch 29/1000\n",
      "1535/1535 [==============================] - 545s 355ms/step - loss: 0.6935 - accuracy: 0.4975 - val_loss: 0.6932 - val_accuracy: 0.5010\n",
      "Epoch 30/1000\n",
      "1535/1535 [==============================] - 547s 356ms/step - loss: 0.6934 - accuracy: 0.4992 - val_loss: 0.6932 - val_accuracy: 0.5011\n",
      "Epoch 31/1000\n",
      "1535/1535 [==============================] - 556s 362ms/step - loss: 0.6935 - accuracy: 0.4981 - val_loss: 0.6932 - val_accuracy: 0.5010\n",
      "Epoch 32/1000\n",
      "1535/1535 [==============================] - 549s 358ms/step - loss: 0.6934 - accuracy: 0.4991 - val_loss: 0.6932 - val_accuracy: 0.5010\n",
      "Epoch 33/1000\n",
      "1535/1535 [==============================] - 550s 358ms/step - loss: 0.6934 - accuracy: 0.4985 - val_loss: 0.6932 - val_accuracy: 0.5010\n",
      "Epoch 34/1000\n",
      "1535/1535 [==============================] - 561s 365ms/step - loss: 0.6935 - accuracy: 0.4994 - val_loss: 0.6932 - val_accuracy: 0.5010\n",
      "Epoch 35/1000\n",
      "1535/1535 [==============================] - 548s 357ms/step - loss: 0.6934 - accuracy: 0.4987 - val_loss: 0.6932 - val_accuracy: 0.5012\n",
      "Epoch 36/1000\n",
      "1535/1535 [==============================] - 550s 358ms/step - loss: 0.6934 - accuracy: 0.4994 - val_loss: 0.6932 - val_accuracy: 0.5011\n",
      "Epoch 37/1000\n",
      "1535/1535 [==============================] - 549s 358ms/step - loss: 0.6934 - accuracy: 0.4988 - val_loss: 0.6932 - val_accuracy: 0.5011\n",
      "Epoch 38/1000\n",
      "1535/1535 [==============================] - 544s 355ms/step - loss: 0.6934 - accuracy: 0.5003 - val_loss: 0.6932 - val_accuracy: 0.5012\n",
      "Epoch 39/1000\n",
      "1535/1535 [==============================] - 560s 365ms/step - loss: 0.6934 - accuracy: 0.4998 - val_loss: 0.6932 - val_accuracy: 0.5012\n",
      "Epoch 40/1000\n",
      "1535/1535 [==============================] - 549s 358ms/step - loss: 0.6935 - accuracy: 0.4988 - val_loss: 0.6932 - val_accuracy: 0.5010\n",
      "Epoch 41/1000\n",
      "1535/1535 [==============================] - 549s 358ms/step - loss: 0.6934 - accuracy: 0.4985 - val_loss: 0.6932 - val_accuracy: 0.5010\n",
      "Epoch 42/1000\n",
      "1535/1535 [==============================] - 557s 363ms/step - loss: 0.6934 - accuracy: 0.4988 - val_loss: 0.6932 - val_accuracy: 0.5010\n",
      "Epoch 43/1000\n",
      "1535/1535 [==============================] - 544s 355ms/step - loss: 0.6934 - accuracy: 0.4999 - val_loss: 0.6932 - val_accuracy: 0.5010\n",
      "Epoch 44/1000\n",
      "1535/1535 [==============================] - 543s 354ms/step - loss: 0.6934 - accuracy: 0.4999 - val_loss: 0.6932 - val_accuracy: 0.5010\n",
      "Epoch 45/1000\n",
      "1535/1535 [==============================] - 533s 347ms/step - loss: 0.6935 - accuracy: 0.4987 - val_loss: 0.6932 - val_accuracy: 0.5010\n",
      "Epoch 46/1000\n",
      "1535/1535 [==============================] - 533s 347ms/step - loss: 0.6934 - accuracy: 0.4996 - val_loss: 0.6932 - val_accuracy: 0.5010\n",
      "Epoch 47/1000\n",
      "1535/1535 [==============================] - 528s 344ms/step - loss: 0.6934 - accuracy: 0.5003 - val_loss: 0.6932 - val_accuracy: 0.5009\n",
      "Epoch 48/1000\n",
      "1535/1535 [==============================] - 527s 343ms/step - loss: 0.6934 - accuracy: 0.4983 - val_loss: 0.6932 - val_accuracy: 0.5009\n",
      "Epoch 49/1000\n",
      "1535/1535 [==============================] - 522s 340ms/step - loss: 0.6935 - accuracy: 0.4985 - val_loss: 0.6932 - val_accuracy: 0.5011\n",
      "Epoch 50/1000\n",
      "1535/1535 [==============================] - 527s 343ms/step - loss: 0.6934 - accuracy: 0.4986 - val_loss: 0.6932 - val_accuracy: 0.5011\n",
      "Epoch 51/1000\n",
      "1535/1535 [==============================] - 531s 346ms/step - loss: 0.6934 - accuracy: 0.4995 - val_loss: 0.6932 - val_accuracy: 0.5012\n",
      "Epoch 52/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1535/1535 [==============================] - 529s 345ms/step - loss: 0.6934 - accuracy: 0.4989 - val_loss: 0.6932 - val_accuracy: 0.5013\n",
      "Epoch 53/1000\n",
      "1535/1535 [==============================] - 520s 339ms/step - loss: 0.6935 - accuracy: 0.4984 - val_loss: 0.6932 - val_accuracy: 0.5013\n",
      "Epoch 54/1000\n",
      "1535/1535 [==============================] - 519s 338ms/step - loss: 0.6934 - accuracy: 0.5001 - val_loss: 0.6932 - val_accuracy: 0.5013\n",
      "Epoch 55/1000\n",
      "1535/1535 [==============================] - 526s 342ms/step - loss: 0.6934 - accuracy: 0.4990 - val_loss: 0.6932 - val_accuracy: 0.5012\n",
      "Epoch 56/1000\n",
      "1535/1535 [==============================] - 519s 338ms/step - loss: 0.6934 - accuracy: 0.4987 - val_loss: 0.6932 - val_accuracy: 0.5012\n",
      "Epoch 57/1000\n",
      "1535/1535 [==============================] - 511s 333ms/step - loss: 0.6935 - accuracy: 0.4996 - val_loss: 0.6932 - val_accuracy: 0.5012\n",
      "Epoch 58/1000\n",
      "1535/1535 [==============================] - 527s 343ms/step - loss: 0.6934 - accuracy: 0.4998 - val_loss: 0.6932 - val_accuracy: 0.5012\n",
      "Epoch 59/1000\n",
      "1535/1535 [==============================] - 523s 341ms/step - loss: 0.6935 - accuracy: 0.4986 - val_loss: 0.6932 - val_accuracy: 0.5012\n",
      "Epoch 60/1000\n",
      "1535/1535 [==============================] - 520s 339ms/step - loss: 0.6934 - accuracy: 0.4995 - val_loss: 0.6932 - val_accuracy: 0.5013\n",
      "Epoch 61/1000\n",
      "1535/1535 [==============================] - 526s 343ms/step - loss: 0.6934 - accuracy: 0.4992 - val_loss: 0.6932 - val_accuracy: 0.5013\n",
      "Epoch 62/1000\n",
      "1535/1535 [==============================] - 524s 342ms/step - loss: 0.6935 - accuracy: 0.4976 - val_loss: 0.6932 - val_accuracy: 0.5013\n",
      "Epoch 63/1000\n",
      "1535/1535 [==============================] - 519s 338ms/step - loss: 0.6935 - accuracy: 0.4995 - val_loss: 0.6932 - val_accuracy: 0.5013\n",
      "Epoch 64/1000\n",
      "1535/1535 [==============================] - 519s 338ms/step - loss: 0.6934 - accuracy: 0.4988 - val_loss: 0.6932 - val_accuracy: 0.5013\n",
      "Epoch 65/1000\n",
      "1535/1535 [==============================] - 525s 342ms/step - loss: 0.6934 - accuracy: 0.4979 - val_loss: 0.6932 - val_accuracy: 0.5014\n",
      "Epoch 66/1000\n",
      "1535/1535 [==============================] - 524s 341ms/step - loss: 0.6934 - accuracy: 0.4987 - val_loss: 0.6932 - val_accuracy: 0.5013\n",
      "Epoch 67/1000\n",
      "1535/1535 [==============================] - 527s 343ms/step - loss: 0.6934 - accuracy: 0.4992 - val_loss: 0.6932 - val_accuracy: 0.5014\n",
      "Epoch 68/1000\n",
      "1535/1535 [==============================] - 527s 343ms/step - loss: 0.6934 - accuracy: 0.4980 - val_loss: 0.6932 - val_accuracy: 0.5014\n",
      "Epoch 69/1000\n",
      "1535/1535 [==============================] - 519s 338ms/step - loss: 0.6934 - accuracy: 0.4991 - val_loss: 0.6932 - val_accuracy: 0.5013\n",
      "Epoch 70/1000\n",
      "1535/1535 [==============================] - 526s 343ms/step - loss: 0.6935 - accuracy: 0.4968 - val_loss: 0.6932 - val_accuracy: 0.5014\n",
      "Epoch 71/1000\n",
      "1535/1535 [==============================] - 521s 339ms/step - loss: 0.6934 - accuracy: 0.4998 - val_loss: 0.6932 - val_accuracy: 0.5014\n",
      "Epoch 72/1000\n",
      "1535/1535 [==============================] - 520s 339ms/step - loss: 0.6934 - accuracy: 0.5007 - val_loss: 0.6932 - val_accuracy: 0.5015\n",
      "Epoch 73/1000\n",
      "1535/1535 [==============================] - 526s 343ms/step - loss: 0.6934 - accuracy: 0.4990 - val_loss: 0.6932 - val_accuracy: 0.5016\n",
      "Epoch 74/1000\n",
      "1535/1535 [==============================] - 524s 341ms/step - loss: 0.6934 - accuracy: 0.4993 - val_loss: 0.6932 - val_accuracy: 0.5017\n",
      "Epoch 75/1000\n",
      "1535/1535 [==============================] - 521s 340ms/step - loss: 0.6935 - accuracy: 0.4990 - val_loss: 0.6932 - val_accuracy: 0.5016\n",
      "Epoch 76/1000\n",
      "1535/1535 [==============================] - 513s 334ms/step - loss: 0.6934 - accuracy: 0.4992 - val_loss: 0.6932 - val_accuracy: 0.5016\n",
      "Epoch 77/1000\n",
      "1535/1535 [==============================] - 523s 341ms/step - loss: 0.6934 - accuracy: 0.5012 - val_loss: 0.6932 - val_accuracy: 0.5016\n",
      "Epoch 78/1000\n",
      "1535/1535 [==============================] - 523s 341ms/step - loss: 0.6935 - accuracy: 0.4979 - val_loss: 0.6932 - val_accuracy: 0.5016\n",
      "Epoch 79/1000\n",
      "1535/1535 [==============================] - 522s 340ms/step - loss: 0.6934 - accuracy: 0.4989 - val_loss: 0.6932 - val_accuracy: 0.5016\n",
      "Epoch 80/1000\n",
      "1535/1535 [==============================] - 526s 343ms/step - loss: 0.6934 - accuracy: 0.4994 - val_loss: 0.6932 - val_accuracy: 0.5015\n",
      "Epoch 81/1000\n",
      "1535/1535 [==============================] - 521s 340ms/step - loss: 0.6934 - accuracy: 0.4998 - val_loss: 0.6932 - val_accuracy: 0.5016\n",
      "Epoch 82/1000\n",
      "1535/1535 [==============================] - 524s 342ms/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5016\n",
      "Epoch 83/1000\n",
      "1535/1535 [==============================] - 520s 339ms/step - loss: 0.6934 - accuracy: 0.4990 - val_loss: 0.6932 - val_accuracy: 0.5016\n",
      "Epoch 84/1000\n",
      "1535/1535 [==============================] - 519s 338ms/step - loss: 0.6934 - accuracy: 0.4993 - val_loss: 0.6932 - val_accuracy: 0.5016\n",
      "Epoch 85/1000\n",
      "1535/1535 [==============================] - 526s 342ms/step - loss: 0.6935 - accuracy: 0.4981 - val_loss: 0.6932 - val_accuracy: 0.5016\n",
      "Epoch 86/1000\n",
      "1535/1535 [==============================] - 521s 339ms/step - loss: 0.6934 - accuracy: 0.4989 - val_loss: 0.6932 - val_accuracy: 0.5015\n",
      "Epoch 87/1000\n",
      "1535/1535 [==============================] - 530s 345ms/step - loss: 0.6934 - accuracy: 0.4997 - val_loss: 0.6932 - val_accuracy: 0.5015\n",
      "Epoch 88/1000\n",
      "1535/1535 [==============================] - 533s 347ms/step - loss: 0.6935 - accuracy: 0.4990 - val_loss: 0.6932 - val_accuracy: 0.5016\n",
      "Epoch 89/1000\n",
      "1535/1535 [==============================] - 525s 342ms/step - loss: 0.6934 - accuracy: 0.4991 - val_loss: 0.6932 - val_accuracy: 0.5016\n",
      "Epoch 90/1000\n",
      "1535/1535 [==============================] - 526s 342ms/step - loss: 0.6934 - accuracy: 0.4993 - val_loss: 0.6932 - val_accuracy: 0.5015\n",
      "Epoch 91/1000\n",
      "1535/1535 [==============================] - 519s 338ms/step - loss: 0.6934 - accuracy: 0.4995 - val_loss: 0.6932 - val_accuracy: 0.5017\n",
      "Epoch 92/1000\n",
      "1535/1535 [==============================] - 529s 345ms/step - loss: 0.6935 - accuracy: 0.4999 - val_loss: 0.6932 - val_accuracy: 0.5017\n",
      "Epoch 93/1000\n",
      "1535/1535 [==============================] - 530s 345ms/step - loss: 0.6934 - accuracy: 0.5002 - val_loss: 0.6932 - val_accuracy: 0.5017\n",
      "Epoch 94/1000\n",
      "1535/1535 [==============================] - 526s 343ms/step - loss: 0.6934 - accuracy: 0.4999 - val_loss: 0.6932 - val_accuracy: 0.5016\n",
      "Epoch 95/1000\n",
      "1535/1535 [==============================] - 524s 341ms/step - loss: 0.6934 - accuracy: 0.5002 - val_loss: 0.6932 - val_accuracy: 0.5016\n",
      "Epoch 96/1000\n",
      "1535/1535 [==============================] - 527s 343ms/step - loss: 0.6934 - accuracy: 0.5006 - val_loss: 0.6932 - val_accuracy: 0.5016\n",
      "Epoch 97/1000\n",
      "1535/1535 [==============================] - 525s 342ms/step - loss: 0.6934 - accuracy: 0.4997 - val_loss: 0.6932 - val_accuracy: 0.5015\n",
      "Epoch 98/1000\n",
      "1535/1535 [==============================] - 523s 341ms/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5015\n",
      "Epoch 99/1000\n",
      "1535/1535 [==============================] - 542s 353ms/step - loss: 0.6934 - accuracy: 0.5010 - val_loss: 0.6932 - val_accuracy: 0.5014\n",
      "Epoch 100/1000\n",
      "1535/1535 [==============================] - 530s 345ms/step - loss: 0.6933 - accuracy: 0.5002 - val_loss: 0.6932 - val_accuracy: 0.5015\n",
      "Epoch 101/1000\n",
      "1535/1535 [==============================] - 517s 337ms/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5017\n",
      "Epoch 102/1000\n",
      "1535/1535 [==============================] - 518s 338ms/step - loss: 0.6934 - accuracy: 0.4997 - val_loss: 0.6932 - val_accuracy: 0.5016\n",
      "Epoch 103/1000\n",
      "1535/1535 [==============================] - 514s 335ms/step - loss: 0.6935 - accuracy: 0.4991 - val_loss: 0.6932 - val_accuracy: 0.5018\n",
      "Epoch 104/1000\n",
      "1535/1535 [==============================] - 516s 336ms/step - loss: 0.6935 - accuracy: 0.4984 - val_loss: 0.6932 - val_accuracy: 0.5017\n",
      "Epoch 105/1000\n",
      "1535/1535 [==============================] - 515s 335ms/step - loss: 0.6934 - accuracy: 0.4989 - val_loss: 0.6932 - val_accuracy: 0.5017\n",
      "Epoch 106/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1535/1535 [==============================] - 514s 335ms/step - loss: 0.6935 - accuracy: 0.4978 - val_loss: 0.6932 - val_accuracy: 0.5016\n",
      "Epoch 107/1000\n",
      "1535/1535 [==============================] - 514s 335ms/step - loss: 0.6935 - accuracy: 0.4990 - val_loss: 0.6932 - val_accuracy: 0.5017\n",
      "Epoch 108/1000\n",
      "1535/1535 [==============================] - 520s 339ms/step - loss: 0.6935 - accuracy: 0.4990 - val_loss: 0.6932 - val_accuracy: 0.5018\n",
      "Epoch 109/1000\n",
      "1535/1535 [==============================] - 513s 334ms/step - loss: 0.6934 - accuracy: 0.4990 - val_loss: 0.6932 - val_accuracy: 0.5017\n",
      "Epoch 110/1000\n",
      "1535/1535 [==============================] - 512s 333ms/step - loss: 0.6934 - accuracy: 0.4989 - val_loss: 0.6932 - val_accuracy: 0.5019\n",
      "Epoch 111/1000\n",
      "1535/1535 [==============================] - 516s 336ms/step - loss: 0.6934 - accuracy: 0.5001 - val_loss: 0.6932 - val_accuracy: 0.5019\n",
      "Epoch 112/1000\n",
      "1535/1535 [==============================] - 527s 343ms/step - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5019\n",
      "Epoch 113/1000\n",
      "1535/1535 [==============================] - 527s 343ms/step - loss: 0.6933 - accuracy: 0.5013 - val_loss: 0.6932 - val_accuracy: 0.5017\n",
      "Epoch 114/1000\n",
      "1535/1535 [==============================] - 522s 340ms/step - loss: 0.6934 - accuracy: 0.5001 - val_loss: 0.6932 - val_accuracy: 0.5019\n",
      "Epoch 115/1000\n",
      "1535/1535 [==============================] - 532s 347ms/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5018\n",
      "Epoch 116/1000\n",
      "1535/1535 [==============================] - 528s 344ms/step - loss: 0.6934 - accuracy: 0.5003 - val_loss: 0.6932 - val_accuracy: 0.5017\n",
      "Epoch 117/1000\n",
      "1535/1535 [==============================] - 524s 342ms/step - loss: 0.6934 - accuracy: 0.4997 - val_loss: 0.6932 - val_accuracy: 0.5017\n",
      "Epoch 118/1000\n",
      "1535/1535 [==============================] - 530s 345ms/step - loss: 0.6934 - accuracy: 0.4990 - val_loss: 0.6932 - val_accuracy: 0.5016\n",
      "Epoch 119/1000\n",
      "1535/1535 [==============================] - 527s 343ms/step - loss: 0.6934 - accuracy: 0.4994 - val_loss: 0.6932 - val_accuracy: 0.5015\n",
      "Epoch 120/1000\n",
      "1535/1535 [==============================] - 530s 345ms/step - loss: 0.6935 - accuracy: 0.4993 - val_loss: 0.6932 - val_accuracy: 0.5015\n",
      "Epoch 121/1000\n",
      "1535/1535 [==============================] - 525s 342ms/step - loss: 0.6935 - accuracy: 0.4985 - val_loss: 0.6932 - val_accuracy: 0.5016\n",
      "Epoch 122/1000\n",
      "1535/1535 [==============================] - 524s 342ms/step - loss: 0.6935 - accuracy: 0.4988 - val_loss: 0.6932 - val_accuracy: 0.5017\n",
      "Epoch 123/1000\n",
      "1535/1535 [==============================] - 533s 347ms/step - loss: 0.6934 - accuracy: 0.4991 - val_loss: 0.6932 - val_accuracy: 0.5016\n",
      "Epoch 124/1000\n",
      "1535/1535 [==============================] - 529s 345ms/step - loss: 0.6934 - accuracy: 0.5004 - val_loss: 0.6932 - val_accuracy: 0.5017\n",
      "Epoch 125/1000\n",
      "1535/1535 [==============================] - 523s 340ms/step - loss: 0.6935 - accuracy: 0.4994 - val_loss: 0.6932 - val_accuracy: 0.5018\n",
      "Epoch 126/1000\n",
      "1535/1535 [==============================] - 534s 348ms/step - loss: 0.6934 - accuracy: 0.5007 - val_loss: 0.6932 - val_accuracy: 0.5019\n",
      "Epoch 127/1000\n",
      "1535/1535 [==============================] - 535s 349ms/step - loss: 0.6934 - accuracy: 0.4987 - val_loss: 0.6932 - val_accuracy: 0.5020\n",
      "Epoch 128/1000\n",
      "1535/1535 [==============================] - 529s 345ms/step - loss: 0.6935 - accuracy: 0.4976 - val_loss: 0.6932 - val_accuracy: 0.5020\n",
      "Epoch 129/1000\n",
      "1535/1535 [==============================] - 527s 343ms/step - loss: 0.6935 - accuracy: 0.4988 - val_loss: 0.6932 - val_accuracy: 0.5020\n",
      "Epoch 130/1000\n",
      "1535/1535 [==============================] - 526s 343ms/step - loss: 0.6935 - accuracy: 0.4999 - val_loss: 0.6932 - val_accuracy: 0.5019\n",
      "Epoch 131/1000\n",
      "1535/1535 [==============================] - 527s 343ms/step - loss: 0.6934 - accuracy: 0.4997 - val_loss: 0.6932 - val_accuracy: 0.5020\n",
      "Epoch 132/1000\n",
      "1535/1535 [==============================] - 521s 339ms/step - loss: 0.6934 - accuracy: 0.4997 - val_loss: 0.6932 - val_accuracy: 0.5020\n",
      "Epoch 133/1000\n",
      "1535/1535 [==============================] - 532s 346ms/step - loss: 0.6934 - accuracy: 0.4997 - val_loss: 0.6932 - val_accuracy: 0.5021\n",
      "Epoch 134/1000\n",
      "1535/1535 [==============================] - 531s 346ms/step - loss: 0.6934 - accuracy: 0.5002 - val_loss: 0.6932 - val_accuracy: 0.5021\n",
      "Epoch 135/1000\n",
      "1535/1535 [==============================] - 530s 345ms/step - loss: 0.6933 - accuracy: 0.5005 - val_loss: 0.6932 - val_accuracy: 0.5023\n",
      "Epoch 136/1000\n",
      "1535/1535 [==============================] - 521s 339ms/step - loss: 0.6935 - accuracy: 0.4999 - val_loss: 0.6932 - val_accuracy: 0.5021\n",
      "Epoch 137/1000\n",
      "1535/1535 [==============================] - 518s 338ms/step - loss: 0.6935 - accuracy: 0.4993 - val_loss: 0.6932 - val_accuracy: 0.5021\n",
      "Epoch 138/1000\n",
      "1535/1535 [==============================] - 520s 339ms/step - loss: 0.6934 - accuracy: 0.5008 - val_loss: 0.6932 - val_accuracy: 0.5022\n",
      "Epoch 139/1000\n",
      "1535/1535 [==============================] - 525s 342ms/step - loss: 0.6934 - accuracy: 0.4989 - val_loss: 0.6932 - val_accuracy: 0.5021\n",
      "Epoch 140/1000\n",
      "1535/1535 [==============================] - 513s 334ms/step - loss: 0.6935 - accuracy: 0.4983 - val_loss: 0.6932 - val_accuracy: 0.5021\n",
      "Epoch 141/1000\n",
      "1535/1535 [==============================] - 514s 335ms/step - loss: 0.6934 - accuracy: 0.4997 - val_loss: 0.6932 - val_accuracy: 0.5022\n",
      "Epoch 142/1000\n",
      "1535/1535 [==============================] - 527s 344ms/step - loss: 0.6934 - accuracy: 0.4991 - val_loss: 0.6932 - val_accuracy: 0.5020\n",
      "Epoch 143/1000\n",
      "1535/1535 [==============================] - 532s 346ms/step - loss: 0.6934 - accuracy: 0.4999 - val_loss: 0.6932 - val_accuracy: 0.5021\n",
      "Epoch 144/1000\n",
      "1535/1535 [==============================] - 522s 340ms/step - loss: 0.6934 - accuracy: 0.5001 - val_loss: 0.6932 - val_accuracy: 0.5020\n",
      "Epoch 145/1000\n",
      "1535/1535 [==============================] - 527s 343ms/step - loss: 0.6934 - accuracy: 0.4990 - val_loss: 0.6932 - val_accuracy: 0.5022\n",
      "Epoch 146/1000\n",
      "1535/1535 [==============================] - 518s 337ms/step - loss: 0.6934 - accuracy: 0.5007 - val_loss: 0.6932 - val_accuracy: 0.5022\n",
      "Epoch 147/1000\n",
      "1535/1535 [==============================] - 525s 342ms/step - loss: 0.6934 - accuracy: 0.5014 - val_loss: 0.6932 - val_accuracy: 0.5021\n",
      "Epoch 148/1000\n",
      "1535/1535 [==============================] - 532s 346ms/step - loss: 0.6934 - accuracy: 0.4999 - val_loss: 0.6932 - val_accuracy: 0.5021\n",
      "Epoch 149/1000\n",
      "1535/1535 [==============================] - 529s 345ms/step - loss: 0.6935 - accuracy: 0.4988 - val_loss: 0.6932 - val_accuracy: 0.5020\n",
      "Epoch 150/1000\n",
      "1535/1535 [==============================] - 525s 342ms/step - loss: 0.6934 - accuracy: 0.5015 - val_loss: 0.6932 - val_accuracy: 0.5020\n",
      "Epoch 151/1000\n",
      "1535/1535 [==============================] - 523s 341ms/step - loss: 0.6935 - accuracy: 0.5001 - val_loss: 0.6932 - val_accuracy: 0.5020\n",
      "Epoch 152/1000\n",
      "1535/1535 [==============================] - 523s 341ms/step - loss: 0.6935 - accuracy: 0.5005 - val_loss: 0.6932 - val_accuracy: 0.5020\n",
      "Epoch 153/1000\n",
      "1535/1535 [==============================] - 523s 340ms/step - loss: 0.6934 - accuracy: 0.5002 - val_loss: 0.6932 - val_accuracy: 0.5022\n",
      "Epoch 154/1000\n",
      "1535/1535 [==============================] - 515s 336ms/step - loss: 0.6935 - accuracy: 0.4990 - val_loss: 0.6932 - val_accuracy: 0.5022\n",
      "Epoch 155/1000\n",
      "1535/1535 [==============================] - 511s 333ms/step - loss: 0.6934 - accuracy: 0.4987 - val_loss: 0.6932 - val_accuracy: 0.5021\n",
      "Epoch 156/1000\n",
      "1535/1535 [==============================] - 515s 336ms/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5023\n",
      "Epoch 157/1000\n",
      "1535/1535 [==============================] - 516s 336ms/step - loss: 0.6934 - accuracy: 0.4988 - val_loss: 0.6932 - val_accuracy: 0.5023\n",
      "Epoch 158/1000\n",
      "1428/1535 [==========================>...] - ETA: 33s - loss: 0.6934 - accuracy: 0.5010"
     ]
    }
   ],
   "source": [
    "timesteps = 240\n",
    "num_input =1\n",
    "num_classes=1\n",
    "label = list(range(timesteps)) + ['target'] + ['ticker'] + ['target_date'] + ['sector']\n",
    "\n",
    "training_data = []\n",
    "training_label = []\n",
    "testing_data =[]\n",
    "testing_label =[]\n",
    "\n",
    "accuracy_results = []\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    # read the data\n",
    "    path  = '/home/RDC/yeungwin/H:/yeungwin/SP500/data/'\n",
    "    train = pd.read_csv(path+'Set_' + str(i) + '_Train.csv', index_col=0).dropna()\n",
    "    test = pd.read_csv(path+'Set_' + str(i) + '_Test.csv', index_col=0).dropna()\n",
    "\n",
    "    train.columns = label\n",
    "    test.columns = label\n",
    "\n",
    "    train_label = train.iloc[:, timesteps]\n",
    "    train_data = train.iloc[:, :timesteps]\n",
    "    test_label = test.iloc[:,timesteps]\n",
    "    test_data = test.iloc[:, :timesteps]\n",
    "    \n",
    "    \n",
    "     # reshape input\n",
    "    #  data: (samples, timesteps, features)\n",
    "    x_train = np.array(train_data).reshape((len(train_data), timesteps, num_input), order = 'F')\n",
    "    x_test = np.array(test_data).reshape((len(test_data), timesteps, num_input), order = 'F')\n",
    "    # label: (samples, target)\n",
    "    y_train = np.array(train_label).reshape((len(train_label), num_classes))\n",
    "    y_test = np.array(test_label).reshape((len(test_label), num_classes))\n",
    "        \n",
    "    print(x_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(x_test.shape)\n",
    "    print(y_test.shape)\n",
    "    \n",
    "    print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "    print(\"Training the model for Training Set \" + str(i) + \" from \" +\n",
    "    datetime.datetime.strftime(datetime.datetime.now(), '%Y-%m-%d %H:%M:%S'))\n",
    "    print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "        \n",
    "    if i ==0:   \n",
    "        tuner = keras_tuner.BayesianOptimization(MyHyperModel(),\n",
    "            objective='val_accuracy',# overwrite=True,\n",
    "            max_trials=30, directory='lstm2', seed=999)\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience = 10)\n",
    "        tuner.search(x_train,y_train, epochs =1000, validation_split=0.2, callbacks=[early_stop])\n",
    "\n",
    "        # save the best model\n",
    "        hypermodel = MyHyperModel()\n",
    "        best_hp = tuner.get_best_hyperparameters()[0]\n",
    "        best_model = hypermodel.build(best_hp)\n",
    "\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience = 10)\n",
    "        result = best_model.fit(x_train,y_train, epochs=1000, validation_split =0.2, verbose =1, callbacks=[early_stop])\n",
    "        print(tuner.get_best_hyperparameters()[0].get_config()[\"values\"])\n",
    "\n",
    "    else: \n",
    "        load_path = '/home/RDC/yeungwin/H:/yeungwin/SP500/5_LSTM/lstm_weight/lstm_weight2.h5'\n",
    "        print('Model restore from ' + load_path)\n",
    "        cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=load_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                    patience = 10)\n",
    "\n",
    "        result = best_model.fit(\n",
    "            x_train, \n",
    "            y_train, \n",
    "            epochs = 1000, \n",
    "            validation_split=0.2,\n",
    "            verbose =1,\n",
    "            callbacks=[cp_callback, early_stop]        \n",
    "        ) \n",
    "            \n",
    "    model_path =\"/home/RDC/yeungwin/H:/yeungwin/SP500/5_LSTM/lstm_weight/lstm_weight2.h5\"    \n",
    "    best_model.save_weights(model_path)\n",
    "    print(\"Model saved to \" + model_path)\n",
    "    print(\"Training end: \" + datetime.datetime.strftime(datetime.datetime.now(), '%Y-%m-%d %H:%M:%S'))\n",
    "        \n",
    "    ##make prediction\n",
    "    pred_ff_test = best_model.predict(x_test)\n",
    "    #pred = pred_ff_test.tolist()\n",
    "    pred = pred_ff_test.reshape((1, len(pred_ff_test))).tolist()[0]\n",
    "    output_data = pd.DataFrame({'y_prob': pred, 'y_true': test['target'], 'Ticker': test['ticker'],\n",
    "                                    'Date': test['target_date'], 'Sector': test['sector'], })\n",
    "    accuracy = accuracy_score(np.round(output_data['y_prob']), output_data['y_true'])\n",
    "    print('Overall Accuracy for test set:'+ str(accuracy))\n",
    "    output_data.to_csv('/home/RDC/yeungwin/H:/yeungwin/SP500/5_LSTM/pred2/lstm_prediction_period_'+str(i)+'.csv')\n",
    "    print('Prediction for period ' + str(i) + ' successfully saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d0fc15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78984d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c80bce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41f11d9c",
   "metadata": {},
   "source": [
    "# For each sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e3bbd07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Healthcare', 'Financials', 'Industrials', 'Consumer Cyclicals', 'Technology', 'Consumer Non-Cyclicals', 'Energy', 'Utilities', 'Real Estate', 'Basic Materials', 'Academic & Educational Services']\n"
     ]
    }
   ],
   "source": [
    "sector = pd.read_csv('/home/RDC/yeungwin/H:/yeungwin/industry_all.csv')\n",
    "sector_list = sector[\"TRBC Economic Sector Name\"].unique()\n",
    "sector_list = [x for x in sector_list if pd.notnull(x)]\n",
    "print(sector_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f6d3653",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sector_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 16\u001b[0m\n\u001b[1;32m     11\u001b[0m accuracy_results \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     12\u001b[0m hyperparameter_records \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sector \u001b[38;5;129;01min\u001b[39;00m sector_list:\n\u001b[1;32m     17\u001b[0m     accuracy_results[sector] \u001b[38;5;241m=\u001b[39m {}  \u001b[38;5;66;03m# Create a sub-dictionary for each sector\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;66;03m# read the data\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sector_list' is not defined"
     ]
    }
   ],
   "source": [
    "timesteps = 240\n",
    "num_input =1\n",
    "num_classes=1\n",
    "label = list(range(timesteps)) + ['target'] + ['ticker'] + ['target_date'] + ['sector']\n",
    "\n",
    "training_data = []\n",
    "training_label = []\n",
    "testing_data =[]\n",
    "testing_label =[]\n",
    "\n",
    "accuracy_results = {}\n",
    "hyperparameter_records = []\n",
    "\n",
    "\n",
    "\n",
    "for sector in sector_list:\n",
    "    accuracy_results[sector] = {}  # Create a sub-dictionary for each sector\n",
    "    for i in range(5):\n",
    "        # read the data\n",
    "        path = '/home/RDC/yeungwin/H:/yeungwin/SP500/data/'\n",
    "        train = pd.read_csv(path+'Set_' + str(i) + '_Train.csv', index_col=0).dropna()\n",
    "        train = train[train['sector']==sector]\n",
    "        test = pd.read_csv(path+'Set_' + str(i) + '_Test.csv', index_col=0).dropna()\n",
    "        test = test[test['sector']==sector]\n",
    "        \n",
    "        train.columns = label\n",
    "        test.columns = label\n",
    "\n",
    "        train_label = train.iloc[:, timesteps]\n",
    "        train_data = train.iloc[:, :timesteps]\n",
    "        test_label = test.iloc[:,timesteps]\n",
    "        test_data = test.iloc[:, :timesteps]\n",
    "\n",
    "\n",
    "         # reshape input\n",
    "        #  data: (samples, timesteps, features)\n",
    "        x_train = np.array(train_data).reshape((len(train_data), timesteps, num_input), order = 'F')\n",
    "        x_test = np.array(test_data).reshape((len(test_data), timesteps, num_input), order = 'F')\n",
    "        # label: (samples, target)\n",
    "        y_train = np.array(train_label).reshape((len(train_label), num_classes))\n",
    "        y_test = np.array(test_label).reshape((len(test_label), num_classes))\n",
    "\n",
    "        print(x_train.shape)\n",
    "        print(y_train.shape)\n",
    "        print(x_test.shape)\n",
    "        print(y_test.shape)\n",
    "\n",
    "        print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "        print(\"Training the model for Training Set \" +sector+ str(i) + \" from \" +\n",
    "        datetime.datetime.strftime(datetime.datetime.now(), '%Y-%m-%d %H:%M:%S'))\n",
    "        print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "        if i==0:\n",
    "            directory_path ='lstm'+sector\n",
    "            tuner = keras_tuner.BayesianOptimization(MyHyperModel(),\n",
    "                objective='val_accuracy',#overwrite=True\n",
    "                max_trials=30, directory=directory_path, seed=111)\n",
    "            tuner.search(x_train,y_train, epochs =3,validation_split=0.2)\n",
    "\n",
    "            # save the best model\n",
    "            hypermodel = MyHyperModel() # the same model but save training to different path\n",
    "            best_hp = tuner.get_best_hyperparameters()[0]\n",
    "            best_model = hypermodel.build(best_hp)\n",
    "            print(sector+\" \")\n",
    "            best_hp_values = tuner.get_best_hyperparameters()[0].get_config()[\"values\"]\n",
    "            print(best_hp_values)\n",
    "            early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                        patience = 10)\n",
    "            result = best_model.fit(x_train,y_train, epochs=1000, validation_split =0.2, verbose =1, callbacks=[early_stop])\n",
    "            hyperparameter_records.append({\n",
    "            \"sector\": sector,\n",
    "            \"hyperparameters\": best_hp_values\n",
    "        })\n",
    "\n",
    "        else:\n",
    "            load_path = '/home/RDC/yeungwin/H:/yeungwin/SP500/5_LSTM/lstm_weight/lstm_weight_'+sector+'.h5'\n",
    "            print('Model restore from ' + load_path)\n",
    "            cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=load_path,\n",
    "                                                     save_weights_only=True,\n",
    "                                                     verbose=1)\n",
    "            early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                        patience = 10)\n",
    "\n",
    "            result = best_model.fit(\n",
    "                x_train, \n",
    "                y_train, \n",
    "                epochs = 1000, \n",
    "                validation_split=0.2,\n",
    "                verbose =1,\n",
    "                callbacks=[cp_callback, early_stop]        \n",
    "            ) \n",
    "\n",
    "\n",
    "        save_path ='/home/RDC/yeungwin/H:/yeungwin/SP500/5_LSTM/lstm_weight/lstm_weight_'+sector+\".h5\"\n",
    "        best_model.save_weights(save_path)\n",
    "        print(\"Model saved to \" + save_path)\n",
    "        print(\"Training end: \" + datetime.datetime.strftime(datetime.datetime.now(), '%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "        ##make prediction\n",
    "        pred_ff_test = best_model.predict(x_test)\n",
    "        pred = pred_ff_test.reshape((1, len(pred_ff_test))).tolist()[0]\n",
    "        output_data = pd.DataFrame({'y_prob': pred, 'y_true': test['target'], 'Ticker': test['ticker'],\n",
    "                                        'Date': test['target_date'], 'Sector': test['sector'], })\n",
    "        accuracy = accuracy_score(np.round(output_data['y_prob']), output_data['y_true'])\n",
    "        print('Overall Accuracy for test set:'+ str(accuracy))\n",
    "        accuracy_results[sector][i] = accuracy\n",
    "\n",
    "        output_data.to_csv('/home/RDC/yeungwin/H:/yeungwin/SP500/5_LSTM/lstm_pred/lstm_'+sector + '_prediction_period_'+str(i)+'.csv')\n",
    "        print('Prediction for period ' +sector + str(i) + ' successfully saved.')\n",
    "        \n",
    "accuracy_df = pd.DataFrame(accuracy_results)\n",
    "hyperparameter_df = pd.DataFrame(hyperparameter_records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d8186c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8265197e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hyperparameter_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaf422d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-tf]",
   "language": "python",
   "name": "conda-env-.conda-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
