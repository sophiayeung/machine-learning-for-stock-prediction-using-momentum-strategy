{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4706621",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, InputLayer, LSTM, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score\n",
    "import keras_tuner\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78b6380f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyHyperModel(keras_tuner.HyperModel):\n",
    "    def build(self,hp):\n",
    "        model = Sequential()\n",
    "        model.add(InputLayer(input_shape=(240,1 ))) #1, 240,1\n",
    "        hp_units = hp.Choice('units', values=[32,64,128])\n",
    "        hp_lr = hp.Choice('learning_rate', values=[1e-6,1e-7,1e-8])\n",
    "        hp_regulariers = hp.Choice('regularies', values = ['l1','l2', 'None'])\n",
    "        if hp_regulariers == 'l1':\n",
    "            regularizers = keras.regularizers.L1(hp_lr)\n",
    "        elif hp_regulariers == 'l2':\n",
    "            regularizers = keras.regularizers.L2(hp_lr)\n",
    "        elif hp_regulariers == 'None':\n",
    "            regularizers = None\n",
    "        \n",
    "        model.add(LSTM(units=hp_units,kernel_regularizer=regularizers,return_sequences =True, name='dense_0'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(LSTM(units=16))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        hp_optimizer = hp.Choice('optimizer', values=['sgd', 'rmsprop', 'adam',\"adamax\"])\n",
    "        if hp_optimizer == 'sgd':\n",
    "            optimizer = keras.optimizers.SGD(learning_rate=hp_lr)\n",
    "        elif hp_optimizer == 'rmsprop':\n",
    "            optimizer = keras.optimizers.RMSprop(learning_rate=hp_lr)\n",
    "        elif hp_optimizer == 'adam':\n",
    "            optimizer = keras.optimizers.Adam(learning_rate=hp_lr)\n",
    "        elif hp_optimizer == 'adamax':\n",
    "            optimizer = keras.optimizers.Adamax(learning_rate=hp_lr)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid optimizer choice\")\n",
    "\n",
    "        model.compile(\n",
    "            optimizer = optimizer\n",
    "            ,loss=keras.losses.BinaryCrossentropy()\n",
    "            , metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "\n",
    "    def fit(self, hp, model, *args, **kwargs):\n",
    "            return model.fit(\n",
    "                *args,\n",
    "                batch_size=hp.Choice(\"batch_size\", [16,32,64,128]),\n",
    "                **kwargs,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff5c7c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(245464, 240, 1)\n",
      "(245464, 1)\n",
      "(120328, 240, 1)\n",
      "(120328, 1)\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training the model for Training Set 0 from 2024-03-10 10:45:17\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "64                |64                |units\n",
      "1e-07             |1e-07             |learning_rate\n",
      "l2                |l2                |regularies\n",
      "sgd               |sgd               |optimizer\n",
      "\n",
      "Epoch 1/100\n",
      "12274/12274 [==============================] - 3696s 300ms/step - loss: 0.6933 - accuracy: 0.5013 - val_loss: 0.6932 - val_accuracy: 0.4987\n",
      "Epoch 2/100\n",
      "12274/12274 [==============================] - 3618s 295ms/step - loss: 0.6934 - accuracy: 0.5015 - val_loss: 0.6932 - val_accuracy: 0.4987\n",
      "Epoch 3/100\n",
      "12274/12274 [==============================] - 3572s 291ms/step - loss: 0.6933 - accuracy: 0.5007 - val_loss: 0.6932 - val_accuracy: 0.4987\n",
      "Epoch 4/100\n",
      "12274/12274 [==============================] - 3551s 289ms/step - loss: 0.6933 - accuracy: 0.5004 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 5/100\n",
      "12274/12274 [==============================] - 3595s 293ms/step - loss: 0.6933 - accuracy: 0.4997 - val_loss: 0.6932 - val_accuracy: 0.4985\n",
      "Epoch 6/100\n",
      "12274/12274 [==============================] - 3553s 289ms/step - loss: 0.6934 - accuracy: 0.4994 - val_loss: 0.6932 - val_accuracy: 0.4983\n",
      "Epoch 7/100\n",
      "12274/12274 [==============================] - 3570s 291ms/step - loss: 0.6933 - accuracy: 0.4997 - val_loss: 0.6932 - val_accuracy: 0.4984\n",
      "Epoch 8/100\n",
      "12274/12274 [==============================] - 3571s 291ms/step - loss: 0.6934 - accuracy: 0.4997 - val_loss: 0.6932 - val_accuracy: 0.4982\n",
      "Epoch 9/100\n",
      "12274/12274 [==============================] - 3542s 289ms/step - loss: 0.6933 - accuracy: 0.5002 - val_loss: 0.6932 - val_accuracy: 0.4983\n",
      "Epoch 10/100\n",
      "12274/12274 [==============================] - 3608s 294ms/step - loss: 0.6933 - accuracy: 0.5009 - val_loss: 0.6932 - val_accuracy: 0.4985\n",
      "Epoch 11/100\n",
      "12274/12274 [==============================] - 3593s 293ms/step - loss: 0.6933 - accuracy: 0.5006 - val_loss: 0.6932 - val_accuracy: 0.4985\n",
      "Epoch 12/100\n",
      "12274/12274 [==============================] - 3646s 297ms/step - loss: 0.6934 - accuracy: 0.5001 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 13/100\n",
      "12274/12274 [==============================] - 3693s 301ms/step - loss: 0.6933 - accuracy: 0.5017 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 14/100\n",
      "12274/12274 [==============================] - 3668s 299ms/step - loss: 0.6934 - accuracy: 0.4980 - val_loss: 0.6932 - val_accuracy: 0.4987\n",
      "Epoch 15/100\n",
      "12274/12274 [==============================] - 3686s 300ms/step - loss: 0.6933 - accuracy: 0.5006 - val_loss: 0.6932 - val_accuracy: 0.4988\n",
      "Epoch 16/100\n",
      "12274/12274 [==============================] - 3600s 293ms/step - loss: 0.6933 - accuracy: 0.4996 - val_loss: 0.6932 - val_accuracy: 0.4989\n",
      "Epoch 17/100\n",
      "12274/12274 [==============================] - 3621s 295ms/step - loss: 0.6934 - accuracy: 0.5002 - val_loss: 0.6932 - val_accuracy: 0.4985\n",
      "Epoch 18/100\n",
      "12274/12274 [==============================] - 3686s 300ms/step - loss: 0.6934 - accuracy: 0.4997 - val_loss: 0.6932 - val_accuracy: 0.4988\n",
      "Epoch 19/100\n",
      "12274/12274 [==============================] - 3496s 285ms/step - loss: 0.6933 - accuracy: 0.5009 - val_loss: 0.6932 - val_accuracy: 0.4987\n",
      "Epoch 20/100\n",
      "12274/12274 [==============================] - 3507s 286ms/step - loss: 0.6933 - accuracy: 0.5014 - val_loss: 0.6932 - val_accuracy: 0.4988\n",
      "Epoch 21/100\n",
      "12274/12274 [==============================] - 3522s 287ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.4990\n",
      "Epoch 22/100\n",
      "12274/12274 [==============================] - 3555s 290ms/step - loss: 0.6934 - accuracy: 0.5003 - val_loss: 0.6932 - val_accuracy: 0.4989\n",
      "Epoch 23/100\n",
      "12274/12274 [==============================] - 3563s 290ms/step - loss: 0.6934 - accuracy: 0.4989 - val_loss: 0.6932 - val_accuracy: 0.4991\n",
      "Epoch 24/100\n",
      "12274/12274 [==============================] - 3397s 277ms/step - loss: 0.6934 - accuracy: 0.4986 - val_loss: 0.6932 - val_accuracy: 0.4992\n",
      "Epoch 25/100\n",
      "12274/12274 [==============================] - 3451s 281ms/step - loss: 0.6933 - accuracy: 0.5005 - val_loss: 0.6932 - val_accuracy: 0.4991\n",
      "Epoch 26/100\n",
      "12274/12274 [==============================] - 3491s 284ms/step - loss: 0.6934 - accuracy: 0.5002 - val_loss: 0.6932 - val_accuracy: 0.4993\n",
      "Epoch 27/100\n",
      " 5818/12274 [=============>................] - ETA: 30:19 - loss: 0.6934 - accuracy: 0.4991"
     ]
    }
   ],
   "source": [
    "timesteps = 240\n",
    "num_input =1\n",
    "num_classes=1\n",
    "label = list(range(timesteps)) + ['target'] + ['ticker'] + ['target_date'] + ['sector']\n",
    "\n",
    "training_data = []\n",
    "training_label = []\n",
    "testing_data =[]\n",
    "testing_label =[]\n",
    "\n",
    "accuracy_results = []\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    # read the data\n",
    "    path  = '/home/RDC/yeungwin/H:/yeungwin/SP500/data/'\n",
    "    train = pd.read_csv(path+'Set_' + str(i) + '_Train.csv', index_col=0).dropna()\n",
    "    test = pd.read_csv(path+'Set_' + str(i) + '_Test.csv', index_col=0).dropna()\n",
    "\n",
    "    train.columns = label\n",
    "    test.columns = label\n",
    "\n",
    "    train_label = train.iloc[:, timesteps]\n",
    "    train_data = train.iloc[:, :timesteps]\n",
    "    test_label = test.iloc[:,timesteps]\n",
    "    test_data = test.iloc[:, :timesteps]\n",
    "    \n",
    "    \n",
    "     # reshape input\n",
    "    #  data: (samples, timesteps, features)\n",
    "    x_train = np.array(train_data).reshape((len(train_data), timesteps, num_input), order = 'F')\n",
    "    x_test = np.array(test_data).reshape((len(test_data), timesteps, num_input), order = 'F')\n",
    "    # label: (samples, target)\n",
    "    y_train = np.array(train_label).reshape((len(train_label), num_classes))\n",
    "    y_test = np.array(test_label).reshape((len(test_label), num_classes))\n",
    "        \n",
    "    print(x_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(x_test.shape)\n",
    "    print(y_test.shape)\n",
    "    \n",
    "    print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "    print(\"Training the model for Training Set \" + str(i) + \" from \" +\n",
    "    datetime.datetime.strftime(datetime.datetime.now(), '%Y-%m-%d %H:%M:%S'))\n",
    "    print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "        \n",
    "    if i ==0:   \n",
    "        tuner = keras_tuner.BayesianOptimization(MyHyperModel(),\n",
    "            objective='val_accuracy',# overwrite=True,\n",
    "            max_trials=5, directory='lstm12', seed=12345)\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience =10)\n",
    "        tuner.search(x_train,y_train, epochs =100, validation_split=0.2, callbacks=[early_stop])\n",
    "\n",
    "        # save the best model\n",
    "        hypermodel = MyHyperModel()\n",
    "        best_hp = tuner.get_best_hyperparameters()[0]\n",
    "        best_model = hypermodel.build(best_hp)\n",
    "\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience = 10)\n",
    "        result = best_model.fit(x_train,y_train, epochs=1000, validation_split =0.2, verbose =1, callbacks=[early_stop])\n",
    "        print(tuner.get_best_hyperparameters()[0].get_config()[\"values\"])\n",
    "\n",
    "    else: \n",
    "        load_path = '/home/RDC/yeungwin/H:/yeungwin/SP500/5_LSTM/lstm_weight/lstm_weight12.h5'\n",
    "        print('Model restore from ' + load_path)\n",
    "        cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=load_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                    patience = 10)\n",
    "\n",
    "        result = best_model.fit(\n",
    "            x_train, \n",
    "            y_train, \n",
    "            epochs = 1000, \n",
    "            validation_split=0.2,\n",
    "            verbose =1,\n",
    "            callbacks=[cp_callback, early_stop]        \n",
    "        ) \n",
    "            \n",
    "    model_path =\"/home/RDC/yeungwin/H:/yeungwin/SP500/5_LSTM/lstm_weight/lstm_weight12.h5\"    \n",
    "    best_model.save_weights(model_path)\n",
    "    print(\"Model saved to \" + model_path)\n",
    "    print(\"Training end: \" + datetime.datetime.strftime(datetime.datetime.now(), '%Y-%m-%d %H:%M:%S'))\n",
    "        \n",
    "    ##make prediction\n",
    "    pred_ff_test = best_model.predict(x_test)\n",
    "    #pred = pred_ff_test.tolist()\n",
    "    pred = pred_ff_test.reshape((1, len(pred_ff_test))).tolist()[0]\n",
    "    output_data = pd.DataFrame({'y_prob': pred, 'y_true': test['target'], 'Ticker': test['ticker'],\n",
    "                                    'Date': test['target_date'], 'Sector': test['sector'], })\n",
    "    accuracy = accuracy_score(np.round(output_data['y_prob']), output_data['y_true'])\n",
    "    print('Overall Accuracy for test set:'+ str(accuracy))\n",
    "    output_data.to_csv('/home/RDC/yeungwin/H:/yeungwin/SP500/5_LSTM/pred12/lstm_prediction_period_'+str(i)+'.csv')\n",
    "    print('Prediction for period ' + str(i) + ' successfully saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe9e693",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09f3c3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8741089",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b95a70a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-tf]",
   "language": "python",
   "name": "conda-env-.conda-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
