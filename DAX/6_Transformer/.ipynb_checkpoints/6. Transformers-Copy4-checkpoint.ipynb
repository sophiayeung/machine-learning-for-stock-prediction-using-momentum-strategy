{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/fredblair/transformers-for-stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,InputLayer, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "#from tcn import TCN,tcn_full_summary\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import keras_tuner\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer model\n",
    "n_timesteps, n_features = 240, 1\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim,\n",
    "                        dropout=0.5, attention_axes=None):\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(\n",
    "      key_dim=head_size, num_heads=num_heads, dropout=dropout,\n",
    "      attention_axes=attention_axes\n",
    "      )(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return x + res\n",
    "\n",
    "def build_transformer(head_size, \n",
    "                      num_heads,\n",
    "                      ff_dim,\n",
    "                      num_trans_blocks,\n",
    "                      mlp_units, dropout, mlp_dropout, activation) -> tf.keras.Model:\n",
    "    #n_timesteps, n_features, n_outputs = 240, 1, 1\n",
    "    inputs = tf.keras.Input(shape=(n_timesteps, n_features))\n",
    "    x = inputs \n",
    "    \n",
    "    for _ in range(num_trans_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=activation)(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "    return tf.keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "def build_model(hp):\n",
    "    head_size = hp.Choice(\"head_size\",[32,64,128]) #embeding size for attention\n",
    "    num_heads = hp.Choice(\"num_heads\",[4,8,16])  #number of attention head\n",
    "    ff_dim =  hp.Choice(\"ff_dim\",[8,16,32])# hidden layer size in FNN insider transformer\n",
    "    activation = hp.Choice(\"activation\",[\"elu\",\"relu\",\"selu\",\"tanh\"])\n",
    "    num_trans_blocks=  hp.Choice(\"num_trans_blocks\",[8,16,32])\n",
    "    #dropout = hp.Choice(\"drop_out\",[0.3,0.5,0.7])\n",
    "    #mlp_dropout= hp.Choice(\"mlp_dropout\",[0.3,0.5,0.7])\n",
    "    model = build_transformer(head_size, num_heads,ff_dim,num_trans_blocks,[256], 0.5, 0.5,activation)\n",
    "    hp_lr = hp.Choice('learning_rate', values=[1e-6,1e-7,1e-8])\n",
    "    hp_optimizer = hp.Choice('optimizer', values=['sgd', 'rmsprop', 'adam',\"adamax\"])\n",
    "    if hp_optimizer == 'sgd':\n",
    "        optimizer = keras.optimizers.SGD(learning_rate=hp_lr)\n",
    "    elif hp_optimizer == 'rmsprop':\n",
    "        optimizer = keras.optimizers.RMSprop(learning_rate=hp_lr)\n",
    "    elif hp_optimizer == 'adam':\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=hp_lr)\n",
    "    elif hp_optimizer == 'adamax':\n",
    "        optimizer = keras.optimizers.Adamax(learning_rate=hp_lr)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid optimizer choice\")\n",
    "\n",
    "    model.compile(optimizer = hp_optimizer,loss=keras.losses.BinaryCrossentropy(), metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from tf0/untitled_project/tuner0.json\n",
      "Search space summary\n",
      "Default search space size: 7\n",
      "head_size (Choice)\n",
      "{'default': 32, 'conditions': [], 'values': [32, 64, 128], 'ordered': True}\n",
      "num_heads (Choice)\n",
      "{'default': 4, 'conditions': [], 'values': [4, 8, 16], 'ordered': True}\n",
      "ff_dim (Choice)\n",
      "{'default': 2, 'conditions': [], 'values': [2, 4, 8, 16, 32], 'ordered': True}\n",
      "activation (Choice)\n",
      "{'default': 'elu', 'conditions': [], 'values': ['elu', 'relu', 'selu', 'tanh'], 'ordered': False}\n",
      "num_trans_blocks (Choice)\n",
      "{'default': 2, 'conditions': [], 'values': [2, 4, 8, 16], 'ordered': True}\n",
      "learning_rate (Choice)\n",
      "{'default': 1e-06, 'conditions': [], 'values': [1e-06, 1e-07, 1e-08], 'ordered': True}\n",
      "optimizer (Choice)\n",
      "{'default': 'sgd', 'conditions': [], 'values': ['sgd', 'rmsprop', 'adam', 'adamax'], 'ordered': False}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "tuner = keras_tuner.BayesianOptimization(build_model,\n",
    "            objective='val_accuracy',\n",
    "            max_trials=55, directory='tf4', seed=100)\n",
    "print(tuner.search_space_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [02h 53m 08s]\n",
      "val_accuracy: 0.5050951242446899\n",
      "\n",
      "Best val_accuracy So Far: 0.553328812122345\n",
      "Total elapsed time: 3d 07h 47m 14s\n",
      "{'head_size': 64, 'num_heads': 16, 'ff_dim': 8, 'activation': 'relu', 'num_trans_blocks': 2, 'learning_rate': 1e-07, 'optimizer': 'rmsprop'}\n",
      "Epoch 1/1000\n",
      "368/368 [==============================] - 221s 593ms/step - loss: 0.7805 - accuracy: 0.5062 - val_loss: 0.7053 - val_accuracy: 0.5031\n",
      "Epoch 2/1000\n",
      "368/368 [==============================] - 218s 592ms/step - loss: 0.6935 - accuracy: 0.5314 - val_loss: 0.7005 - val_accuracy: 0.5207\n",
      "Epoch 3/1000\n",
      "368/368 [==============================] - 205s 558ms/step - loss: 0.6744 - accuracy: 0.5686 - val_loss: 0.6964 - val_accuracy: 0.5228\n",
      "Epoch 4/1000\n",
      "368/368 [==============================] - 213s 579ms/step - loss: 0.6586 - accuracy: 0.5975 - val_loss: 0.6985 - val_accuracy: 0.5343\n",
      "Epoch 5/1000\n",
      "368/368 [==============================] - 212s 577ms/step - loss: 0.6312 - accuracy: 0.6321 - val_loss: 0.7010 - val_accuracy: 0.5296\n",
      "Epoch 6/1000\n",
      "368/368 [==============================] - 214s 583ms/step - loss: 0.6024 - accuracy: 0.6615 - val_loss: 0.7154 - val_accuracy: 0.5329\n",
      "Epoch 7/1000\n",
      "368/368 [==============================] - 215s 583ms/step - loss: 0.5846 - accuracy: 0.6746 - val_loss: 0.7304 - val_accuracy: 0.5377\n",
      "Epoch 8/1000\n",
      "368/368 [==============================] - 216s 588ms/step - loss: 0.5594 - accuracy: 0.7014 - val_loss: 0.7411 - val_accuracy: 0.5302\n",
      "Epoch 9/1000\n",
      "368/368 [==============================] - 216s 587ms/step - loss: 0.5394 - accuracy: 0.7243 - val_loss: 0.7392 - val_accuracy: 0.5350\n",
      "Epoch 10/1000\n",
      "368/368 [==============================] - 212s 576ms/step - loss: 0.5159 - accuracy: 0.7470 - val_loss: 0.7655 - val_accuracy: 0.5503\n",
      "Epoch 11/1000\n",
      "368/368 [==============================] - 208s 565ms/step - loss: 0.4999 - accuracy: 0.7549 - val_loss: 0.7736 - val_accuracy: 0.5459\n",
      "Epoch 12/1000\n",
      "368/368 [==============================] - 216s 587ms/step - loss: 0.4812 - accuracy: 0.7664 - val_loss: 0.8106 - val_accuracy: 0.5435\n",
      "Epoch 13/1000\n",
      "368/368 [==============================] - 215s 585ms/step - loss: 0.4730 - accuracy: 0.7703 - val_loss: 0.8468 - val_accuracy: 0.5319\n",
      "Model saved to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "Training end: 2024-02-10 05:22:11\n",
      "224/224 [==============================] - 40s 179ms/step\n",
      "Overall Accuracy for test set:0.49685270667226183\n",
      "Prediction for period 0 successfully saved.\n",
      "(14569, 240, 1)\n",
      "(14569, 1)\n",
      "(7500, 240, 1)\n",
      "(7500, 1)\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training the model for Training Set 1 from 2024-02-10 05:22:56\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model restore from /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "Epoch 1/1000\n",
      "365/365 [==============================] - ETA: 0s - loss: 0.6310 - accuracy: 0.6365\n",
      "Epoch 1: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "365/365 [==============================] - 213s 584ms/step - loss: 0.6310 - accuracy: 0.6365 - val_loss: 0.7998 - val_accuracy: 0.5079\n",
      "Epoch 2/1000\n",
      "365/365 [==============================] - ETA: 0s - loss: 0.6091 - accuracy: 0.6534\n",
      "Epoch 2: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "365/365 [==============================] - 216s 592ms/step - loss: 0.6091 - accuracy: 0.6534 - val_loss: 0.8047 - val_accuracy: 0.5120\n",
      "Epoch 3/1000\n",
      "365/365 [==============================] - ETA: 0s - loss: 0.5807 - accuracy: 0.6699\n",
      "Epoch 3: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "365/365 [==============================] - 215s 589ms/step - loss: 0.5807 - accuracy: 0.6699 - val_loss: 0.8789 - val_accuracy: 0.5141\n",
      "Epoch 4/1000\n",
      "365/365 [==============================] - ETA: 0s - loss: 0.5717 - accuracy: 0.6864\n",
      "Epoch 4: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "365/365 [==============================] - 214s 586ms/step - loss: 0.5717 - accuracy: 0.6864 - val_loss: 0.8011 - val_accuracy: 0.5165\n",
      "Epoch 5/1000\n",
      "365/365 [==============================] - ETA: 0s - loss: 0.5514 - accuracy: 0.6934\n",
      "Epoch 5: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "365/365 [==============================] - 211s 579ms/step - loss: 0.5514 - accuracy: 0.6934 - val_loss: 0.8412 - val_accuracy: 0.5055\n",
      "Epoch 6/1000\n",
      "365/365 [==============================] - ETA: 0s - loss: 0.5434 - accuracy: 0.7001\n",
      "Epoch 6: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "365/365 [==============================] - 206s 565ms/step - loss: 0.5434 - accuracy: 0.7001 - val_loss: 0.8277 - val_accuracy: 0.5213\n",
      "Epoch 7/1000\n",
      "365/365 [==============================] - ETA: 0s - loss: 0.5395 - accuracy: 0.7038\n",
      "Epoch 7: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "365/365 [==============================] - 217s 596ms/step - loss: 0.5395 - accuracy: 0.7038 - val_loss: 0.8211 - val_accuracy: 0.5168\n",
      "Epoch 8/1000\n",
      "365/365 [==============================] - ETA: 0s - loss: 0.5267 - accuracy: 0.7121\n",
      "Epoch 8: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "365/365 [==============================] - 211s 579ms/step - loss: 0.5267 - accuracy: 0.7121 - val_loss: 0.8679 - val_accuracy: 0.5196\n",
      "Epoch 9/1000\n",
      "365/365 [==============================] - ETA: 0s - loss: 0.5182 - accuracy: 0.7175\n",
      "Epoch 9: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "365/365 [==============================] - 183s 502ms/step - loss: 0.5182 - accuracy: 0.7175 - val_loss: 0.9048 - val_accuracy: 0.5199\n",
      "Epoch 10/1000\n",
      "365/365 [==============================] - ETA: 0s - loss: 0.5152 - accuracy: 0.7224\n",
      "Epoch 10: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "365/365 [==============================] - 207s 568ms/step - loss: 0.5152 - accuracy: 0.7224 - val_loss: 0.8954 - val_accuracy: 0.5226\n",
      "Epoch 11/1000\n",
      "365/365 [==============================] - ETA: 0s - loss: 0.5108 - accuracy: 0.7257\n",
      "Epoch 11: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "365/365 [==============================] - 211s 577ms/step - loss: 0.5108 - accuracy: 0.7257 - val_loss: 0.9036 - val_accuracy: 0.5103\n",
      "Model saved to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "Training end: 2024-02-10 06:01:21\n",
      "235/235 [==============================] - 41s 172ms/step\n",
      "Overall Accuracy for test set:0.5045333333333333\n",
      "Prediction for period 1 successfully saved.\n",
      "(14919, 240, 1)\n",
      "(14919, 1)\n",
      "(7448, 240, 1)\n",
      "(7448, 1)\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training the model for Training Set 2 from 2024-02-10 06:02:06\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model restore from /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "Epoch 1/1000\n",
      "373/373 [==============================] - ETA: 0s - loss: 0.7108 - accuracy: 0.5596\n",
      "Epoch 1: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "373/373 [==============================] - 213s 572ms/step - loss: 0.7108 - accuracy: 0.5596 - val_loss: 0.7513 - val_accuracy: 0.4816\n",
      "Epoch 2/1000\n",
      "373/373 [==============================] - ETA: 0s - loss: 0.6871 - accuracy: 0.5703\n",
      "Epoch 2: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "373/373 [==============================] - 211s 565ms/step - loss: 0.6871 - accuracy: 0.5703 - val_loss: 0.7823 - val_accuracy: 0.4990\n",
      "Epoch 3/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "373/373 [==============================] - ETA: 0s - loss: 0.6881 - accuracy: 0.5716\n",
      "Epoch 3: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "373/373 [==============================] - 212s 569ms/step - loss: 0.6881 - accuracy: 0.5716 - val_loss: 0.7778 - val_accuracy: 0.5094\n",
      "Epoch 4/1000\n",
      "373/373 [==============================] - ETA: 0s - loss: 0.6834 - accuracy: 0.5661\n",
      "Epoch 4: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "373/373 [==============================] - 211s 566ms/step - loss: 0.6834 - accuracy: 0.5661 - val_loss: 0.7890 - val_accuracy: 0.5010\n",
      "Epoch 5/1000\n",
      "373/373 [==============================] - ETA: 0s - loss: 0.6857 - accuracy: 0.5684\n",
      "Epoch 5: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "373/373 [==============================] - 212s 569ms/step - loss: 0.6857 - accuracy: 0.5684 - val_loss: 0.8668 - val_accuracy: 0.5054\n",
      "Epoch 6/1000\n",
      "373/373 [==============================] - ETA: 0s - loss: 0.6890 - accuracy: 0.5659\n",
      "Epoch 6: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "373/373 [==============================] - 213s 572ms/step - loss: 0.6890 - accuracy: 0.5659 - val_loss: 0.8024 - val_accuracy: 0.5057\n",
      "Epoch 7/1000\n",
      "373/373 [==============================] - ETA: 0s - loss: 0.6885 - accuracy: 0.5809\n",
      "Epoch 7: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "373/373 [==============================] - 218s 585ms/step - loss: 0.6885 - accuracy: 0.5809 - val_loss: 0.8079 - val_accuracy: 0.4863\n",
      "Epoch 8/1000\n",
      "373/373 [==============================] - ETA: 0s - loss: 0.6812 - accuracy: 0.5868\n",
      "Epoch 8: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "373/373 [==============================] - 212s 569ms/step - loss: 0.6812 - accuracy: 0.5868 - val_loss: 0.7997 - val_accuracy: 0.4956\n",
      "Epoch 9/1000\n",
      "373/373 [==============================] - ETA: 0s - loss: 0.6746 - accuracy: 0.5825\n",
      "Epoch 9: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "373/373 [==============================] - 211s 566ms/step - loss: 0.6746 - accuracy: 0.5825 - val_loss: 0.8380 - val_accuracy: 0.5027\n",
      "Epoch 10/1000\n",
      "373/373 [==============================] - ETA: 0s - loss: 0.6661 - accuracy: 0.5883\n",
      "Epoch 10: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "373/373 [==============================] - 210s 564ms/step - loss: 0.6661 - accuracy: 0.5883 - val_loss: 0.8253 - val_accuracy: 0.5010\n",
      "Epoch 11/1000\n",
      "373/373 [==============================] - ETA: 0s - loss: 0.6708 - accuracy: 0.5968\n",
      "Epoch 11: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "373/373 [==============================] - 208s 559ms/step - loss: 0.6708 - accuracy: 0.5968 - val_loss: 0.8298 - val_accuracy: 0.5030\n",
      "Model saved to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "Training end: 2024-02-10 06:40:58\n",
      "233/233 [==============================] - 41s 177ms/step\n",
      "Overall Accuracy for test set:0.5048335123523093\n",
      "Prediction for period 2 successfully saved.\n",
      "(15248, 240, 1)\n",
      "(15248, 1)\n",
      "(7058, 240, 1)\n",
      "(7058, 1)\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training the model for Training Set 3 from 2024-02-10 06:42:24\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model restore from /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "Epoch 1/1000\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.7221 - accuracy: 0.5200\n",
      "Epoch 1: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "382/382 [==============================] - 211s 552ms/step - loss: 0.7221 - accuracy: 0.5200 - val_loss: 0.7137 - val_accuracy: 0.5039\n",
      "Epoch 2/1000\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.7035 - accuracy: 0.5183\n",
      "Epoch 2: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "382/382 [==============================] - 204s 535ms/step - loss: 0.7035 - accuracy: 0.5183 - val_loss: 0.7379 - val_accuracy: 0.4915\n",
      "Epoch 3/1000\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.7036 - accuracy: 0.5143\n",
      "Epoch 3: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "382/382 [==============================] - 218s 570ms/step - loss: 0.7036 - accuracy: 0.5143 - val_loss: 0.7122 - val_accuracy: 0.4803\n",
      "Epoch 4/1000\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.7066 - accuracy: 0.5231\n",
      "Epoch 4: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "382/382 [==============================] - 215s 564ms/step - loss: 0.7066 - accuracy: 0.5231 - val_loss: 0.7074 - val_accuracy: 0.5003\n",
      "Epoch 5/1000\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.7016 - accuracy: 0.5184\n",
      "Epoch 5: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "382/382 [==============================] - 214s 559ms/step - loss: 0.7016 - accuracy: 0.5184 - val_loss: 0.7926 - val_accuracy: 0.5030\n",
      "Epoch 6/1000\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.7056 - accuracy: 0.5122\n",
      "Epoch 6: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "382/382 [==============================] - 214s 561ms/step - loss: 0.7056 - accuracy: 0.5122 - val_loss: 0.7367 - val_accuracy: 0.5144\n",
      "Epoch 7/1000\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.7036 - accuracy: 0.5171\n",
      "Epoch 7: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "382/382 [==============================] - 213s 558ms/step - loss: 0.7036 - accuracy: 0.5171 - val_loss: 0.7187 - val_accuracy: 0.5010\n",
      "Epoch 8/1000\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.7071 - accuracy: 0.5131\n",
      "Epoch 8: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "382/382 [==============================] - 214s 561ms/step - loss: 0.7071 - accuracy: 0.5131 - val_loss: 0.7402 - val_accuracy: 0.5141\n",
      "Epoch 9/1000\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.6999 - accuracy: 0.5189\n",
      "Epoch 9: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "382/382 [==============================] - 215s 563ms/step - loss: 0.6999 - accuracy: 0.5189 - val_loss: 0.7171 - val_accuracy: 0.5003\n",
      "Epoch 10/1000\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.7051 - accuracy: 0.5252\n",
      "Epoch 10: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "382/382 [==============================] - 216s 565ms/step - loss: 0.7051 - accuracy: 0.5252 - val_loss: 0.7185 - val_accuracy: 0.4980\n",
      "Epoch 11/1000\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.7101 - accuracy: 0.5278\n",
      "Epoch 11: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "382/382 [==============================] - 219s 573ms/step - loss: 0.7101 - accuracy: 0.5278 - val_loss: 0.7561 - val_accuracy: 0.5121\n",
      "Epoch 12/1000\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.7055 - accuracy: 0.5180\n",
      "Epoch 12: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "382/382 [==============================] - 219s 574ms/step - loss: 0.7055 - accuracy: 0.5180 - val_loss: 0.7181 - val_accuracy: 0.4961\n",
      "Epoch 13/1000\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.7092 - accuracy: 0.5248\n",
      "Epoch 13: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382/382 [==============================] - 219s 573ms/step - loss: 0.7092 - accuracy: 0.5248 - val_loss: 0.7245 - val_accuracy: 0.5039\n",
      "Epoch 14/1000\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.7075 - accuracy: 0.5243\n",
      "Epoch 14: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "382/382 [==============================] - 211s 553ms/step - loss: 0.7075 - accuracy: 0.5243 - val_loss: 0.7696 - val_accuracy: 0.4898\n",
      "Model saved to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "Training end: 2024-02-10 07:32:27\n",
      "221/221 [==============================] - 38s 174ms/step\n",
      "Overall Accuracy for test set:0.5049589118730519\n",
      "Prediction for period 3 successfully saved.\n",
      "(14806, 240, 1)\n",
      "(14806, 1)\n",
      "(7175, 240, 1)\n",
      "(7175, 1)\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training the model for Training Set 4 from 2024-02-10 07:33:10\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model restore from /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "Epoch 1/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.7052 - accuracy: 0.5091\n",
      "Epoch 1: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "371/371 [==============================] - 209s 564ms/step - loss: 0.7052 - accuracy: 0.5091 - val_loss: 0.7001 - val_accuracy: 0.4909\n",
      "Epoch 2/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6975 - accuracy: 0.5075\n",
      "Epoch 2: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "371/371 [==============================] - 205s 553ms/step - loss: 0.6975 - accuracy: 0.5075 - val_loss: 0.7536 - val_accuracy: 0.5007\n",
      "Epoch 3/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6976 - accuracy: 0.5067\n",
      "Epoch 3: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "371/371 [==============================] - 197s 531ms/step - loss: 0.6976 - accuracy: 0.5067 - val_loss: 0.6963 - val_accuracy: 0.4868\n",
      "Epoch 4/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6940 - accuracy: 0.5057\n",
      "Epoch 4: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "371/371 [==============================] - 208s 562ms/step - loss: 0.6940 - accuracy: 0.5057 - val_loss: 0.6949 - val_accuracy: 0.4858\n",
      "Epoch 5/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6946 - accuracy: 0.5062\n",
      "Epoch 5: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "371/371 [==============================] - 208s 561ms/step - loss: 0.6946 - accuracy: 0.5062 - val_loss: 0.7050 - val_accuracy: 0.4841\n",
      "Epoch 6/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6947 - accuracy: 0.5071\n",
      "Epoch 6: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "371/371 [==============================] - 208s 561ms/step - loss: 0.6947 - accuracy: 0.5071 - val_loss: 0.6977 - val_accuracy: 0.4841\n",
      "Epoch 7/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6940 - accuracy: 0.5051\n",
      "Epoch 7: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "371/371 [==============================] - 213s 575ms/step - loss: 0.6940 - accuracy: 0.5051 - val_loss: 0.6963 - val_accuracy: 0.4882\n",
      "Epoch 8/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6948 - accuracy: 0.5060\n",
      "Epoch 8: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "371/371 [==============================] - 211s 569ms/step - loss: 0.6948 - accuracy: 0.5060 - val_loss: 0.6965 - val_accuracy: 0.4845\n",
      "Epoch 9/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6952 - accuracy: 0.5057\n",
      "Epoch 9: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "371/371 [==============================] - 207s 558ms/step - loss: 0.6952 - accuracy: 0.5057 - val_loss: 0.6975 - val_accuracy: 0.4851\n",
      "Epoch 10/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6953 - accuracy: 0.5055\n",
      "Epoch 10: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "371/371 [==============================] - 206s 556ms/step - loss: 0.6953 - accuracy: 0.5055 - val_loss: 0.6964 - val_accuracy: 0.4875\n",
      "Epoch 11/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6957 - accuracy: 0.5073\n",
      "Epoch 11: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "371/371 [==============================] - 206s 556ms/step - loss: 0.6957 - accuracy: 0.5073 - val_loss: 0.6981 - val_accuracy: 0.4905\n",
      "Epoch 12/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6949 - accuracy: 0.5075\n",
      "Epoch 12: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "371/371 [==============================] - 207s 559ms/step - loss: 0.6949 - accuracy: 0.5075 - val_loss: 0.6968 - val_accuracy: 0.4878\n",
      "Epoch 13/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6944 - accuracy: 0.5056\n",
      "Epoch 13: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "371/371 [==============================] - 212s 571ms/step - loss: 0.6944 - accuracy: 0.5056 - val_loss: 0.6962 - val_accuracy: 0.4862\n",
      "Epoch 14/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6940 - accuracy: 0.5064\n",
      "Epoch 14: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "371/371 [==============================] - 208s 561ms/step - loss: 0.6940 - accuracy: 0.5064 - val_loss: 0.6959 - val_accuracy: 0.4851\n",
      "Model saved to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5\n",
      "Training end: 2024-02-10 08:21:37\n",
      "225/225 [==============================] - 39s 175ms/step\n",
      "Overall Accuracy for test set:0.4995121951219512\n",
      "Prediction for period 4 successfully saved.\n"
     ]
    }
   ],
   "source": [
    "timesteps = 240\n",
    "num_input =1\n",
    "num_classes=1\n",
    "label = list(range(timesteps)) + ['target'] + ['ticker'] + ['target_date'] + ['sector']\n",
    "\n",
    "training_data = []\n",
    "training_label = []\n",
    "testing_data =[]\n",
    "testing_label =[]\n",
    "\n",
    "accuracy_results = []\n",
    "\n",
    "for i in range(5):\n",
    "    # read the data\n",
    "    path = '/home/RDC/yeungwin/H:/yeungwin/DAX/data/'\n",
    "    train = pd.read_csv(path+'Set_' + str(i) + '_Train.csv', index_col=0).dropna()\n",
    "    test = pd.read_csv(path+'Set_' + str(i) + '_Test.csv', index_col=0).dropna()\n",
    "\n",
    "    train.columns = label\n",
    "    test.columns = label\n",
    "\n",
    "    train_label = train.iloc[:, timesteps]\n",
    "    train_data = train.iloc[:, :timesteps]\n",
    "    test_label = test.iloc[:,timesteps]\n",
    "    test_data = test.iloc[:, :timesteps]\n",
    "    \n",
    "    \n",
    "     # reshape input\n",
    "    #  data: (samples, timesteps, features)\n",
    "    x_train = np.array(train_data).reshape((len(train_data), timesteps, num_input), order = 'F')\n",
    "    x_test = np.array(test_data).reshape((len(test_data), timesteps, num_input), order = 'F')\n",
    "    # label: (samples, target)\n",
    "    y_train = np.array(train_label).reshape((len(train_label), num_classes))\n",
    "    y_test = np.array(test_label).reshape((len(test_label), num_classes))\n",
    "        \n",
    "    print(x_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(x_test.shape)\n",
    "    print(y_test.shape)\n",
    "    \n",
    "    print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "    print(\"Training the model for Training Set \" + str(i) + \" from \" +\n",
    "    datetime.datetime.strftime(datetime.datetime.now(), '%Y-%m-%d %H:%M:%S'))\n",
    "    print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "        \n",
    "    if i==0:\n",
    "        tuner = keras_tuner.BayesianOptimization(build_model,\n",
    "            objective='val_accuracy',\n",
    "            max_trials=40, directory='tf4', seed=111)\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience =10, restore_best_weights=False)\n",
    "        tuner.search(x_train,y_train, epochs =1000,validation_split=0.2, callbacks=[early_stop])\n",
    "\n",
    "        # save the best model\n",
    "        #hypermodel =build_model\n",
    "        best_hp = tuner.get_best_hyperparameters()[0]\n",
    "        best_model = build_model(best_hp)\n",
    "        print(tuner.get_best_hyperparameters()[0].get_config()[\"values\"])\n",
    "\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience =10, restore_best_weights=False)\n",
    "        result = best_model.fit(x_train,y_train, epochs=1000, validation_split =0.2, verbose =1, callbacks=[early_stop])\n",
    "\n",
    "        \n",
    "    else:\n",
    "        load_path = '/home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5'\n",
    "        print('Model restore from ' + load_path)\n",
    "        cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=load_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                    patience = 10, restore_best_weights=False)\n",
    "\n",
    "        result = best_model.fit(\n",
    "            x_train, \n",
    "            y_train, \n",
    "            epochs = 1000, \n",
    "            validation_split=0.2,\n",
    "            verbose =1,\n",
    "            callbacks=[cp_callback, early_stop]        \n",
    "        ) \n",
    "        \n",
    "    save_path =  '/home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight4.h5'\n",
    "    best_model.save_weights(save_path)\n",
    "    print(\"Model saved to \" + save_path)\n",
    "    print(\"Training end: \" + datetime.datetime.strftime(datetime.datetime.now(), '%Y-%m-%d %H:%M:%S'))\n",
    "        \n",
    "    ##make prediction\n",
    "    pred_ff_test = best_model.predict(x_test)\n",
    "    #pred = pred_ff_test.tolist()\n",
    "    pred = pred_ff_test.reshape((1, len(pred_ff_test))).tolist()[0]\n",
    "    output_data = pd.DataFrame({'y_prob': pred, 'y_true': test['target'], 'Ticker': test['ticker'],\n",
    "                                    'Date': test['target_date'], 'Sector': test['sector'], })\n",
    "    accuracy = accuracy_score(np.round(output_data['y_prob']), output_data['y_true'])\n",
    "    print('Overall Accuracy for test set:'+ str(accuracy))\n",
    "    \n",
    "    \n",
    "    output_data.to_csv('/home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/pred4/tf_prediction_period_'+str(i)+'.csv')\n",
    "    print('Prediction for period ' + str(i) + ' successfully saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model for each sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Basic Materials', 'Consumer Cyclicals', 'Financials', 'Healthcare', 'Consumer Non-Cyclicals', 'Industrials', 'Technology', 'Real Estate', 'Utilities']\n"
     ]
    }
   ],
   "source": [
    "sector = pd.read_csv('/home/RDC/yeungwin/H:/yeungwin/DAX/8_performance/stock_analysis.csv')\n",
    "sector_list = sector[\"Sector\"].unique().tolist()\n",
    "print(sector_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 00m 08s]\n",
      "\n",
      "Best val_accuracy So Far: None\n",
      "Total elapsed time: 00h 00m 18s\n",
      "\n",
      "Search: Running Trial #3\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "128               |128               |head_size\n",
      "8                 |8                 |num_heads\n",
      "2                 |2                 |ff_dim\n",
      "tanh              |elu               |activation\n",
      "8                 |16                |num_trans_blocks\n",
      "1e-07             |1e-08             |learning_rate\n",
      "rmsprop           |sgd               |optimizer\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/RDC/yeungwin/.conda/envs/tf/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py\", line 273, in _try_run_and_update_trial\n",
      "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"/home/RDC/yeungwin/.conda/envs/tf/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py\", line 238, in _run_and_update_trial\n",
      "    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/RDC/yeungwin/.conda/envs/tf/lib/python3.11/site-packages/keras_tuner/src/engine/tuner.py\", line 314, in run_trial\n",
      "    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/RDC/yeungwin/.conda/envs/tf/lib/python3.11/site-packages/keras_tuner/src/engine/tuner.py\", line 233, in _build_and_fit_model\n",
      "    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/RDC/yeungwin/.conda/envs/tf/lib/python3.11/site-packages/keras_tuner/src/engine/hypermodel.py\", line 149, in fit\n",
      "    return model.fit(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/RDC/yeungwin/.conda/envs/tf/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/RDC/yeungwin/.conda/envs/tf/lib/python3.11/site-packages/keras/src/engine/data_adapter.py\", line 1795, in train_validation_split\n",
      "    raise ValueError(\n",
      "ValueError: Training data contains 0 samples, which is not sufficient to split it into a validation and training set as specified by `validation_split=0.2`. Either provide more data, or a different value for the `validation_split` argument.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Number of consecutive failures exceeded the limit of 3.\nTraceback (most recent call last):\n  File \"/home/RDC/yeungwin/.conda/envs/tf/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py\", line 273, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"/home/RDC/yeungwin/.conda/envs/tf/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py\", line 238, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/RDC/yeungwin/.conda/envs/tf/lib/python3.11/site-packages/keras_tuner/src/engine/tuner.py\", line 314, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/RDC/yeungwin/.conda/envs/tf/lib/python3.11/site-packages/keras_tuner/src/engine/tuner.py\", line 233, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/RDC/yeungwin/.conda/envs/tf/lib/python3.11/site-packages/keras_tuner/src/engine/hypermodel.py\", line 149, in fit\n    return model.fit(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/RDC/yeungwin/.conda/envs/tf/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/home/RDC/yeungwin/.conda/envs/tf/lib/python3.11/site-packages/keras/src/engine/data_adapter.py\", line 1795, in train_validation_split\n    raise ValueError(\nValueError: Training data contains 0 samples, which is not sufficient to split it into a validation and training set as specified by `validation_split=0.2`. Either provide more data, or a different value for the `validation_split` argument.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 54\u001b[0m\n\u001b[1;32m     50\u001b[0m tuner \u001b[38;5;241m=\u001b[39m keras_tuner\u001b[38;5;241m.\u001b[39mBayesianOptimization(build_model,\n\u001b[1;32m     51\u001b[0m     objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;66;03m# overwrite=True,\u001b[39;00m\n\u001b[1;32m     52\u001b[0m     max_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, directory\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39msector, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m111\u001b[39m)\n\u001b[1;32m     53\u001b[0m early_stop \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m )\n\u001b[0;32m---> 54\u001b[0m tuner\u001b[38;5;241m.\u001b[39msearch(x_train,y_train, epochs \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39m[early_stop])\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# save the best model\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m#hypermodel =build_model\u001b[39;00m\n\u001b[1;32m     58\u001b[0m best_hp \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mget_best_hyperparameters()[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py:234\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_run_and_update_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py:338\u001b[0m, in \u001b[0;36mBaseTuner.on_trial_end\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_trial_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Called at the end of a trial.\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \n\u001b[1;32m    335\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m        trial: A `Trial` instance.\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 338\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mend_trial(trial)\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave()\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.11/site-packages/keras_tuner/src/engine/oracle.py:108\u001b[0m, in \u001b[0;36msynchronized.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m     LOCKS[oracle]\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m    107\u001b[0m     THREADS[oracle] \u001b[38;5;241m=\u001b[39m thread_name\n\u001b[0;32m--> 108\u001b[0m ret_val \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m need_acquire:\n\u001b[1;32m    110\u001b[0m     THREADS[oracle] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.11/site-packages/keras_tuner/src/engine/oracle.py:577\u001b[0m, in \u001b[0;36mOracle.end_trial\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry(trial):\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_order\u001b[38;5;241m.\u001b[39mappend(trial\u001b[38;5;241m.\u001b[39mtrial_id)\n\u001b[0;32m--> 577\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_consecutive_failures()\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_trial(trial)\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave()\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.11/site-packages/keras_tuner/src/engine/oracle.py:534\u001b[0m, in \u001b[0;36mOracle._check_consecutive_failures\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    532\u001b[0m     consecutive_failures \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m consecutive_failures \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_consecutive_failed_trials:\n\u001b[0;32m--> 534\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    535\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of consecutive failures exceeded the limit \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    536\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_consecutive_failed_trials\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    537\u001b[0m         \u001b[38;5;241m+\u001b[39m (trial\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    538\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Number of consecutive failures exceeded the limit of 3.\nTraceback (most recent call last):\n  File \"/home/RDC/yeungwin/.conda/envs/tf/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py\", line 273, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"/home/RDC/yeungwin/.conda/envs/tf/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py\", line 238, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/RDC/yeungwin/.conda/envs/tf/lib/python3.11/site-packages/keras_tuner/src/engine/tuner.py\", line 314, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/RDC/yeungwin/.conda/envs/tf/lib/python3.11/site-packages/keras_tuner/src/engine/tuner.py\", line 233, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/RDC/yeungwin/.conda/envs/tf/lib/python3.11/site-packages/keras_tuner/src/engine/hypermodel.py\", line 149, in fit\n    return model.fit(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/RDC/yeungwin/.conda/envs/tf/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/home/RDC/yeungwin/.conda/envs/tf/lib/python3.11/site-packages/keras/src/engine/data_adapter.py\", line 1795, in train_validation_split\n    raise ValueError(\nValueError: Training data contains 0 samples, which is not sufficient to split it into a validation and training set as specified by `validation_split=0.2`. Either provide more data, or a different value for the `validation_split` argument.\n"
     ]
    }
   ],
   "source": [
    "timesteps = 240\n",
    "num_input =1\n",
    "num_classes=1\n",
    "label = list(range(timesteps)) + ['target'] + ['ticker'] + ['target_date'] + ['sector']\n",
    "\n",
    "training_data = []\n",
    "training_label = []\n",
    "testing_data =[]\n",
    "testing_label =[]\n",
    "\n",
    "accuracy_results = []\n",
    "\n",
    "for sector in sector_list:\n",
    "    for i in range(5):\n",
    "        # read the data\n",
    "        path = '/home/RDC/yeungwin/H:/yeungwin/DAX/data/'\n",
    "        train = pd.read_csv(path+'Set_' + str(i) + '_Train.csv', index_col=0).dropna()\n",
    "        train = train[train.sector == sector]\n",
    "        test = pd.read_csv(path+'Set_' + str(i) + '_Test.csv', index_col=0).dropna()\n",
    "        test = test[test.sector == sector]\n",
    "\n",
    "        train.columns = label\n",
    "        test.columns = label\n",
    "\n",
    "        train_label = train.iloc[:, timesteps]\n",
    "        train_data = train.iloc[:, :timesteps]\n",
    "        test_label = test.iloc[:,timesteps]\n",
    "        test_data = test.iloc[:, :timesteps]\n",
    "\n",
    "\n",
    "         # reshape input\n",
    "        #  data: (samples, timesteps, features)\n",
    "        x_train = np.array(train_data).reshape((len(train_data), timesteps, num_input), order = 'F')\n",
    "        x_test = np.array(test_data).reshape((len(test_data), timesteps, num_input), order = 'F')\n",
    "        # label: (samples, target)\n",
    "        y_train = np.array(train_label).reshape((len(train_label), num_classes))\n",
    "        y_test = np.array(test_label).reshape((len(test_label), num_classes))\n",
    "\n",
    "        print(x_train.shape)\n",
    "        print(y_train.shape)\n",
    "        print(x_test.shape)\n",
    "        print(y_test.shape)\n",
    "\n",
    "        print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "        print(\"Training the model for Training Set \" + str(i) + \" from \" +\n",
    "        datetime.datetime.strftime(datetime.datetime.now(), '%Y-%m-%d %H:%M:%S'))\n",
    "        print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "        if i==0:\n",
    "            tuner = keras_tuner.BayesianOptimization(build_model,\n",
    "                objective='val_accuracy',# overwrite=True,\n",
    "                max_trials=10, directory='tf_'+sector, seed=111)\n",
    "            early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience =3 )\n",
    "            tuner.search(x_train,y_train, epochs =100,validation_split=0.2, callbacks=[early_stop])\n",
    "\n",
    "            # save the best model\n",
    "            #hypermodel =build_model\n",
    "            best_hp = tuner.get_best_hyperparameters()[0]\n",
    "            best_model = build_model(best_hp)\n",
    "            print(tuner.get_best_hyperparameters()[0].get_config()[\"values\"])\n",
    "\n",
    "            early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 10)\n",
    "            result = best_model.fit(x_train,y_train, epochs=1000, batch_size=64,validation_split =0.2, verbose =1, callbacks=[early_stop])\n",
    "\n",
    "        else:\n",
    "            load_path = '/home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight_'+sector+'.h5'\n",
    "            print('Model restore from ' + load_path)\n",
    "            cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=load_path,\n",
    "                                                     save_weights_only=True,\n",
    "                                                     verbose=1)\n",
    "            early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                        patience = 10)\n",
    "\n",
    "            result = best_model.fit(\n",
    "                x_train, \n",
    "                y_train, \n",
    "                epochs = 1000, \n",
    "                validation_split=0.2,\n",
    "                verbose =1,\n",
    "                callbacks=[cp_callback, early_stop]        \n",
    "            ) \n",
    "            \n",
    "\n",
    "        save_path = \"/home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight_\"+sector+\".h5\"\n",
    "        best_model.save_weights(save_path)\n",
    "        print(\"Model saved to \" + save_path)\n",
    "        print(\"Training end: \" + datetime.datetime.strftime(datetime.datetime.now(), '%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "        ##make prediction\n",
    "        pred_ff_test = best_model.predict(x_test)\n",
    "        #pred = pred_ff_test.tolist()\n",
    "        pred = pred_ff_test.reshape((1, len(pred_ff_test))).tolist()[0]\n",
    "        output_data = pd.DataFrame({'y_prob': pred, 'y_true': test['target'], 'Ticker': test['ticker'],\n",
    "                                        'Date': test['target_date'], 'Sector': test['sector'], })\n",
    "        accuracy = accuracy_score(np.round(output_data['y_prob']), output_data['y_true'])\n",
    "        print('Overall Accuracy for test set:'+ str(accuracy))\n",
    "\n",
    "\n",
    "        output_data.to_csv('/home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/tf_pred/tf_prediction_period_'+sector+'_'+str(i)+'.csv')\n",
    "        print('Prediction for period ' + str(i) + ' successfully saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-tf]",
   "language": "python",
   "name": "conda-env-.conda-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
