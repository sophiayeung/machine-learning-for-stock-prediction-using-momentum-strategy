{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,InputLayer, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "#from tcn import TCN,tcn_full_summary\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import keras_tuner\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer model\n",
    "n_timesteps, n_features = 240, 1\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim,\n",
    "                        dropout=0, attention_axes=None):\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(\n",
    "      key_dim=head_size, num_heads=num_heads, dropout=dropout,\n",
    "      attention_axes=attention_axes\n",
    "      )(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return x + res\n",
    "\n",
    "def build_transformer(head_size, \n",
    "                      num_heads,\n",
    "                      ff_dim,\n",
    "                      num_trans_blocks,\n",
    "                      mlp_units, dropout, mlp_dropout, activation) -> tf.keras.Model:\n",
    "    #n_timesteps, n_features, n_outputs = 240, 1, 1\n",
    "    inputs = tf.keras.Input(shape=(n_timesteps, n_features))\n",
    "    x = inputs \n",
    "    \n",
    "    for _ in range(num_trans_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=activation)(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "    return tf.keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "def build_model(hp):\n",
    "    head_size = hp.Choice(\"head_size\",[32,64,128,256]) #embeding size for attention\n",
    "    num_heads = hp.Choice(\"num_heads\",[4,8,16,32])  #number of attention head\n",
    "    ff_dim =  hp.Choice(\"ff_dim\",[8,16,32,64])# hidden layer size in FNN insider transformer\n",
    "    activation = hp.Choice(\"activation\",[\"elu\",\"relu\",\"selu\",\"tanh\"])\n",
    "    num_trans_blocks=  hp.Choice(\"num_trans_blocks\",[8,16,32])\n",
    "    model = build_transformer(head_size, num_heads,ff_dim,num_trans_blocks,[256], 0.5, 0.5,activation)\n",
    "    hp_lr = hp.Choice('learning_rate', values=[1e-6,1e-7,1e-8])\n",
    "    hp_optimizer = hp.Choice('optimizer', values=['sgd', 'rmsprop', 'adam',\"adamax\"])\n",
    "    if hp_optimizer == 'sgd':\n",
    "        optimizer = keras.optimizers.SGD(learning_rate=hp_lr)\n",
    "    elif hp_optimizer == 'rmsprop':\n",
    "        optimizer = keras.optimizers.RMSprop(learning_rate=hp_lr)\n",
    "    elif hp_optimizer == 'adam':\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=hp_lr)\n",
    "    elif hp_optimizer == 'adamax':\n",
    "        optimizer = keras.optimizers.Adamax(learning_rate=hp_lr)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid optimizer choice\")\n",
    "\n",
    "    model.compile(optimizer = hp_optimizer,loss=keras.losses.BinaryCrossentropy(), metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [01h 39m 16s]\n",
      "val_accuracy: 0.5288723111152649\n",
      "\n",
      "Best val_accuracy So Far: 0.5366848111152649\n",
      "Total elapsed time: 4d 08h 58m 56s\n",
      "{'head_size': 128, 'num_heads': 32, 'ff_dim': 16, 'activation': 'relu', 'num_trans_blocks': 16, 'learning_rate': 1e-08, 'optimizer': 'rmsprop'}\n",
      "Epoch 1/1000\n",
      "368/368 [==============================] - 1387s 4s/step - loss: 0.8250 - accuracy: 0.5011 - val_loss: 0.7139 - val_accuracy: 0.5105\n",
      "Epoch 2/1000\n",
      "368/368 [==============================] - 1361s 4s/step - loss: 0.7007 - accuracy: 0.5362 - val_loss: 0.6997 - val_accuracy: 0.5044\n",
      "Epoch 3/1000\n",
      "368/368 [==============================] - 1364s 4s/step - loss: 0.6754 - accuracy: 0.5702 - val_loss: 0.6963 - val_accuracy: 0.5299\n",
      "Epoch 4/1000\n",
      "368/368 [==============================] - 1367s 4s/step - loss: 0.6510 - accuracy: 0.6107 - val_loss: 0.7023 - val_accuracy: 0.5200\n",
      "Epoch 5/1000\n",
      "368/368 [==============================] - 1365s 4s/step - loss: 0.6273 - accuracy: 0.6428 - val_loss: 0.7095 - val_accuracy: 0.5285\n",
      "Epoch 6/1000\n",
      "368/368 [==============================] - 1362s 4s/step - loss: 0.5976 - accuracy: 0.6736 - val_loss: 0.7241 - val_accuracy: 0.5292\n",
      "Epoch 7/1000\n",
      "368/368 [==============================] - 1367s 4s/step - loss: 0.5764 - accuracy: 0.7001 - val_loss: 0.7335 - val_accuracy: 0.5316\n",
      "Epoch 8/1000\n",
      "368/368 [==============================] - 1365s 4s/step - loss: 0.5485 - accuracy: 0.7230 - val_loss: 0.7222 - val_accuracy: 0.5479\n",
      "Epoch 9/1000\n",
      "368/368 [==============================] - 1375s 4s/step - loss: 0.5230 - accuracy: 0.7434 - val_loss: 0.7744 - val_accuracy: 0.5428\n",
      "Epoch 10/1000\n",
      "368/368 [==============================] - 1390s 4s/step - loss: 0.5066 - accuracy: 0.7570 - val_loss: 0.8070 - val_accuracy: 0.5404\n",
      "Epoch 11/1000\n",
      "368/368 [==============================] - 1393s 4s/step - loss: 0.4931 - accuracy: 0.7729 - val_loss: 0.7755 - val_accuracy: 0.5493\n",
      "Epoch 12/1000\n",
      "368/368 [==============================] - 1399s 4s/step - loss: 0.4722 - accuracy: 0.7813 - val_loss: 0.8228 - val_accuracy: 0.5438\n",
      "Epoch 13/1000\n",
      "368/368 [==============================] - 1422s 4s/step - loss: 0.4536 - accuracy: 0.7941 - val_loss: 0.8233 - val_accuracy: 0.5380\n",
      "Model saved to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "Training end: 2024-03-14 11:49:34\n",
      "224/224 [==============================] - 267s 1s/step\n",
      "Overall Accuracy for test set:0.4948943908238915\n",
      "Prediction for period 0 successfully saved.\n",
      "(14569, 240, 1)\n",
      "(14569, 1)\n",
      "(7500, 240, 1)\n",
      "(7500, 1)\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training the model for Training Set 1 from 2024-03-14 11:54:05\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model restore from /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "Epoch 1/1000\n",
      "365/365 [==============================] - ETA: 0s - loss: 0.6423 - accuracy: 0.6263\n",
      "Epoch 1: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "365/365 [==============================] - 1434s 4s/step - loss: 0.6423 - accuracy: 0.6263 - val_loss: 0.7282 - val_accuracy: 0.5192\n",
      "Epoch 2/1000\n",
      "365/365 [==============================] - ETA: 0s - loss: 0.6281 - accuracy: 0.6424\n",
      "Epoch 2: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "365/365 [==============================] - 1440s 4s/step - loss: 0.6281 - accuracy: 0.6424 - val_loss: 0.9944 - val_accuracy: 0.5041\n",
      "Epoch 3/1000\n",
      "365/365 [==============================] - ETA: 0s - loss: 0.6040 - accuracy: 0.6560\n",
      "Epoch 3: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "365/365 [==============================] - 1439s 4s/step - loss: 0.6040 - accuracy: 0.6560 - val_loss: 0.8769 - val_accuracy: 0.5031\n",
      "Epoch 4/1000\n",
      "365/365 [==============================] - ETA: 0s - loss: 0.5809 - accuracy: 0.6824\n",
      "Epoch 4: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "365/365 [==============================] - 1434s 4s/step - loss: 0.5809 - accuracy: 0.6824 - val_loss: 0.7802 - val_accuracy: 0.5148\n",
      "Epoch 5/1000\n",
      "365/365 [==============================] - ETA: 0s - loss: 0.5600 - accuracy: 0.6914\n",
      "Epoch 5: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "365/365 [==============================] - 1424s 4s/step - loss: 0.5600 - accuracy: 0.6914 - val_loss: 0.8282 - val_accuracy: 0.5069\n",
      "Epoch 6/1000\n",
      "365/365 [==============================] - ETA: 0s - loss: 0.5499 - accuracy: 0.7029\n",
      "Epoch 6: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "365/365 [==============================] - 1434s 4s/step - loss: 0.5499 - accuracy: 0.7029 - val_loss: 0.8474 - val_accuracy: 0.5292\n",
      "Epoch 7/1000\n",
      "365/365 [==============================] - ETA: 0s - loss: 0.5333 - accuracy: 0.7115\n",
      "Epoch 7: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "365/365 [==============================] - 1430s 4s/step - loss: 0.5333 - accuracy: 0.7115 - val_loss: 0.8124 - val_accuracy: 0.5154\n",
      "Epoch 8/1000\n",
      "365/365 [==============================] - ETA: 0s - loss: 0.5233 - accuracy: 0.7226\n",
      "Epoch 8: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "365/365 [==============================] - 1432s 4s/step - loss: 0.5233 - accuracy: 0.7226 - val_loss: 0.8537 - val_accuracy: 0.5089\n",
      "Epoch 9/1000\n",
      "365/365 [==============================] - ETA: 0s - loss: 0.5063 - accuracy: 0.7350\n",
      "Epoch 9: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "365/365 [==============================] - 1430s 4s/step - loss: 0.5063 - accuracy: 0.7350 - val_loss: 0.9242 - val_accuracy: 0.5220\n",
      "Epoch 10/1000\n",
      "365/365 [==============================] - ETA: 0s - loss: 0.4991 - accuracy: 0.7420\n",
      "Epoch 10: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "365/365 [==============================] - 1424s 4s/step - loss: 0.4991 - accuracy: 0.7420 - val_loss: 0.8635 - val_accuracy: 0.5244\n",
      "Epoch 11/1000\n",
      "365/365 [==============================] - ETA: 0s - loss: 0.4873 - accuracy: 0.7538\n",
      "Epoch 11: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "365/365 [==============================] - 1421s 4s/step - loss: 0.4873 - accuracy: 0.7538 - val_loss: 0.8520 - val_accuracy: 0.5264\n",
      "Model saved to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "Training end: 2024-03-14 16:16:28\n",
      "235/235 [==============================] - 274s 1s/step\n",
      "Overall Accuracy for test set:0.49493333333333334\n",
      "Prediction for period 1 successfully saved.\n",
      "(14919, 240, 1)\n",
      "(14919, 1)\n",
      "(7448, 240, 1)\n",
      "(7448, 1)\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training the model for Training Set 2 from 2024-03-14 16:21:06\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model restore from /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "Epoch 1/1000\n",
      "373/373 [==============================] - ETA: 0s - loss: 0.7149 - accuracy: 0.5439\n",
      "Epoch 1: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "373/373 [==============================] - 1471s 4s/step - loss: 0.7149 - accuracy: 0.5439 - val_loss: 0.7106 - val_accuracy: 0.4983\n",
      "Epoch 2/1000\n",
      "373/373 [==============================] - ETA: 0s - loss: 0.7050 - accuracy: 0.5481\n",
      "Epoch 2: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "373/373 [==============================] - 1470s 4s/step - loss: 0.7050 - accuracy: 0.5481 - val_loss: 0.7405 - val_accuracy: 0.4950\n",
      "Epoch 3/1000\n",
      "373/373 [==============================] - ETA: 0s - loss: 0.7035 - accuracy: 0.5445\n",
      "Epoch 3: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "373/373 [==============================] - 1452s 4s/step - loss: 0.7035 - accuracy: 0.5445 - val_loss: 0.7252 - val_accuracy: 0.5077\n",
      "Epoch 4/1000\n",
      "373/373 [==============================] - ETA: 0s - loss: 0.6957 - accuracy: 0.5481\n",
      "Epoch 4: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "373/373 [==============================] - 1455s 4s/step - loss: 0.6957 - accuracy: 0.5481 - val_loss: 0.7395 - val_accuracy: 0.5111\n",
      "Epoch 5/1000\n",
      "373/373 [==============================] - ETA: 0s - loss: 0.6948 - accuracy: 0.5563\n",
      "Epoch 5: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "373/373 [==============================] - 1462s 4s/step - loss: 0.6948 - accuracy: 0.5563 - val_loss: 0.7495 - val_accuracy: 0.5034\n",
      "Epoch 6/1000\n",
      "373/373 [==============================] - ETA: 0s - loss: 0.6895 - accuracy: 0.5651\n",
      "Epoch 6: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "373/373 [==============================] - 1458s 4s/step - loss: 0.6895 - accuracy: 0.5651 - val_loss: 0.7624 - val_accuracy: 0.5090\n",
      "Epoch 7/1000\n",
      "373/373 [==============================] - ETA: 0s - loss: 0.6897 - accuracy: 0.5651\n",
      "Epoch 7: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "373/373 [==============================] - 1451s 4s/step - loss: 0.6897 - accuracy: 0.5651 - val_loss: 0.8093 - val_accuracy: 0.5164\n",
      "Epoch 8/1000\n",
      "373/373 [==============================] - ETA: 0s - loss: 0.6797 - accuracy: 0.5751\n",
      "Epoch 8: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "373/373 [==============================] - 1455s 4s/step - loss: 0.6797 - accuracy: 0.5751 - val_loss: 0.7757 - val_accuracy: 0.5034\n",
      "Epoch 9/1000\n",
      "373/373 [==============================] - ETA: 0s - loss: 0.6814 - accuracy: 0.5746\n",
      "Epoch 9: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "373/373 [==============================] - 1451s 4s/step - loss: 0.6814 - accuracy: 0.5746 - val_loss: 0.7898 - val_accuracy: 0.5084\n",
      "Epoch 10/1000\n",
      "373/373 [==============================] - ETA: 0s - loss: 0.6798 - accuracy: 0.5839\n",
      "Epoch 10: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "373/373 [==============================] - 1460s 4s/step - loss: 0.6798 - accuracy: 0.5839 - val_loss: 0.7770 - val_accuracy: 0.5111\n",
      "Epoch 11/1000\n",
      "373/373 [==============================] - ETA: 0s - loss: 0.6636 - accuracy: 0.6004\n",
      "Epoch 11: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "373/373 [==============================] - 1461s 4s/step - loss: 0.6636 - accuracy: 0.6004 - val_loss: 0.8244 - val_accuracy: 0.5013\n",
      "Model saved to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "Training end: 2024-03-14 20:48:30\n",
      "233/233 [==============================] - 275s 1s/step\n",
      "Overall Accuracy for test set:0.4931525241675618\n",
      "Prediction for period 2 successfully saved.\n",
      "(15248, 240, 1)\n",
      "(15248, 1)\n",
      "(7058, 240, 1)\n",
      "(7058, 1)\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training the model for Training Set 3 from 2024-03-14 20:53:09\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model restore from /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "Epoch 1/1000\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.7132 - accuracy: 0.5140\n",
      "Epoch 1: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "382/382 [==============================] - 1499s 4s/step - loss: 0.7132 - accuracy: 0.5140 - val_loss: 0.7237 - val_accuracy: 0.5230\n",
      "Epoch 2/1000\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.7050 - accuracy: 0.5093\n",
      "Epoch 2: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "382/382 [==============================] - 1490s 4s/step - loss: 0.7050 - accuracy: 0.5093 - val_loss: 0.7500 - val_accuracy: 0.4925\n",
      "Epoch 3/1000\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.7108 - accuracy: 0.5121\n",
      "Epoch 3: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "382/382 [==============================] - 1436s 4s/step - loss: 0.7108 - accuracy: 0.5121 - val_loss: 0.7161 - val_accuracy: 0.4934\n",
      "Epoch 4/1000\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.7009 - accuracy: 0.5106\n",
      "Epoch 4: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "382/382 [==============================] - 1407s 4s/step - loss: 0.7009 - accuracy: 0.5106 - val_loss: 0.7105 - val_accuracy: 0.4915\n",
      "Epoch 5/1000\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.7045 - accuracy: 0.5162\n",
      "Epoch 5: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "382/382 [==============================] - 1412s 4s/step - loss: 0.7045 - accuracy: 0.5162 - val_loss: 0.7714 - val_accuracy: 0.4846\n",
      "Epoch 6/1000\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.7073 - accuracy: 0.5178\n",
      "Epoch 6: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "382/382 [==============================] - 1408s 4s/step - loss: 0.7073 - accuracy: 0.5178 - val_loss: 0.7200 - val_accuracy: 0.4872\n",
      "Epoch 7/1000\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.7019 - accuracy: 0.5182\n",
      "Epoch 7: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "382/382 [==============================] - 1405s 4s/step - loss: 0.7019 - accuracy: 0.5182 - val_loss: 0.7650 - val_accuracy: 0.5131\n",
      "Epoch 8/1000\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.7036 - accuracy: 0.5126\n",
      "Epoch 8: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "382/382 [==============================] - 1405s 4s/step - loss: 0.7036 - accuracy: 0.5126 - val_loss: 0.7210 - val_accuracy: 0.5039\n",
      "Epoch 9/1000\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.7015 - accuracy: 0.5120\n",
      "Epoch 9: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "382/382 [==============================] - 1409s 4s/step - loss: 0.7015 - accuracy: 0.5120 - val_loss: 0.7172 - val_accuracy: 0.5023\n",
      "Epoch 10/1000\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.7038 - accuracy: 0.5156\n",
      "Epoch 10: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "382/382 [==============================] - 1413s 4s/step - loss: 0.7038 - accuracy: 0.5156 - val_loss: 0.7231 - val_accuracy: 0.5046\n",
      "Epoch 11/1000\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.7047 - accuracy: 0.5171\n",
      "Epoch 11: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "382/382 [==============================] - 1416s 4s/step - loss: 0.7047 - accuracy: 0.5171 - val_loss: 0.7294 - val_accuracy: 0.5062\n",
      "Epoch 12/1000\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.7044 - accuracy: 0.5130\n",
      "Epoch 12: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "382/382 [==============================] - 1413s 4s/step - loss: 0.7044 - accuracy: 0.5130 - val_loss: 0.7146 - val_accuracy: 0.5085\n",
      "Epoch 13/1000\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.7042 - accuracy: 0.5105\n",
      "Epoch 13: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "382/382 [==============================] - 1412s 4s/step - loss: 0.7042 - accuracy: 0.5105 - val_loss: 0.7166 - val_accuracy: 0.5138\n",
      "Epoch 14/1000\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.7067 - accuracy: 0.5128\n",
      "Epoch 14: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382/382 [==============================] - 1410s 4s/step - loss: 0.7067 - accuracy: 0.5128 - val_loss: 0.7146 - val_accuracy: 0.5016\n",
      "Model saved to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "Training end: 2024-03-15 02:25:24\n",
      "221/221 [==============================] - 244s 1s/step\n",
      "Overall Accuracy for test set:0.5138849532445452\n",
      "Prediction for period 3 successfully saved.\n",
      "(14806, 240, 1)\n",
      "(14806, 1)\n",
      "(7175, 240, 1)\n",
      "(7175, 1)\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training the model for Training Set 4 from 2024-03-15 02:29:33\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model restore from /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "Epoch 1/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.7020 - accuracy: 0.5094\n",
      "Epoch 1: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "371/371 [==============================] - 1375s 4s/step - loss: 0.7020 - accuracy: 0.5094 - val_loss: 0.6963 - val_accuracy: 0.4855\n",
      "Epoch 2/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6946 - accuracy: 0.5043\n",
      "Epoch 2: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "371/371 [==============================] - 1377s 4s/step - loss: 0.6946 - accuracy: 0.5043 - val_loss: 0.6996 - val_accuracy: 0.4865\n",
      "Epoch 3/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6944 - accuracy: 0.5045\n",
      "Epoch 3: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "371/371 [==============================] - 1374s 4s/step - loss: 0.6944 - accuracy: 0.5045 - val_loss: 0.6968 - val_accuracy: 0.4892\n",
      "Epoch 4/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6946 - accuracy: 0.5071\n",
      "Epoch 4: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "371/371 [==============================] - 1373s 4s/step - loss: 0.6946 - accuracy: 0.5071 - val_loss: 0.7058 - val_accuracy: 0.4828\n",
      "Epoch 5/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6961 - accuracy: 0.5039\n",
      "Epoch 5: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "371/371 [==============================] - 1374s 4s/step - loss: 0.6961 - accuracy: 0.5039 - val_loss: 0.6931 - val_accuracy: 0.4919\n",
      "Epoch 6/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6941 - accuracy: 0.5060\n",
      "Epoch 6: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "371/371 [==============================] - 1375s 4s/step - loss: 0.6941 - accuracy: 0.5060 - val_loss: 0.6945 - val_accuracy: 0.4858\n",
      "Epoch 7/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6963 - accuracy: 0.5066\n",
      "Epoch 7: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "371/371 [==============================] - 1377s 4s/step - loss: 0.6963 - accuracy: 0.5066 - val_loss: 0.6971 - val_accuracy: 0.4865\n",
      "Epoch 8/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6942 - accuracy: 0.5052\n",
      "Epoch 8: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "371/371 [==============================] - 1374s 4s/step - loss: 0.6942 - accuracy: 0.5052 - val_loss: 0.6957 - val_accuracy: 0.4845\n",
      "Epoch 9/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.5048\n",
      "Epoch 9: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "371/371 [==============================] - 1371s 4s/step - loss: 0.6937 - accuracy: 0.5048 - val_loss: 0.6947 - val_accuracy: 0.4841\n",
      "Epoch 10/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6935 - accuracy: 0.5048\n",
      "Epoch 10: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "371/371 [==============================] - 1372s 4s/step - loss: 0.6935 - accuracy: 0.5048 - val_loss: 0.6952 - val_accuracy: 0.4851\n",
      "Epoch 11/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6946 - accuracy: 0.5062\n",
      "Epoch 11: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "371/371 [==============================] - 1374s 4s/step - loss: 0.6946 - accuracy: 0.5062 - val_loss: 0.6978 - val_accuracy: 0.4926\n",
      "Epoch 12/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6964 - accuracy: 0.5075\n",
      "Epoch 12: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "371/371 [==============================] - 1368s 4s/step - loss: 0.6964 - accuracy: 0.5075 - val_loss: 0.7049 - val_accuracy: 0.4895\n",
      "Epoch 13/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6982 - accuracy: 0.5141\n",
      "Epoch 13: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "371/371 [==============================] - 1372s 4s/step - loss: 0.6982 - accuracy: 0.5141 - val_loss: 0.6933 - val_accuracy: 0.4845\n",
      "Epoch 14/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6956 - accuracy: 0.5059\n",
      "Epoch 14: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "371/371 [==============================] - 1369s 4s/step - loss: 0.6956 - accuracy: 0.5059 - val_loss: 0.6949 - val_accuracy: 0.4946\n",
      "Epoch 15/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6962 - accuracy: 0.5073\n",
      "Epoch 15: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "371/371 [==============================] - 1369s 4s/step - loss: 0.6962 - accuracy: 0.5073 - val_loss: 0.6925 - val_accuracy: 0.4936\n",
      "Epoch 16/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6939 - accuracy: 0.5040\n",
      "Epoch 16: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "371/371 [==============================] - 1372s 4s/step - loss: 0.6939 - accuracy: 0.5040 - val_loss: 0.6935 - val_accuracy: 0.4862\n",
      "Epoch 17/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6950 - accuracy: 0.5073\n",
      "Epoch 17: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "371/371 [==============================] - 1372s 4s/step - loss: 0.6950 - accuracy: 0.5073 - val_loss: 0.6945 - val_accuracy: 0.4862\n",
      "Epoch 18/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6944 - accuracy: 0.5060\n",
      "Epoch 18: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "371/371 [==============================] - 1372s 4s/step - loss: 0.6944 - accuracy: 0.5060 - val_loss: 0.6931 - val_accuracy: 0.4835\n",
      "Epoch 19/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6971 - accuracy: 0.5095\n",
      "Epoch 19: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "371/371 [==============================] - 1374s 4s/step - loss: 0.6971 - accuracy: 0.5095 - val_loss: 0.6985 - val_accuracy: 0.4919\n",
      "Epoch 20/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6989 - accuracy: 0.5112\n",
      "Epoch 20: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "371/371 [==============================] - 1381s 4s/step - loss: 0.6989 - accuracy: 0.5112 - val_loss: 0.6965 - val_accuracy: 0.4916\n",
      "Epoch 21/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6944 - accuracy: 0.5075\n",
      "Epoch 21: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "371/371 [==============================] - 1367s 4s/step - loss: 0.6944 - accuracy: 0.5075 - val_loss: 0.7037 - val_accuracy: 0.4885\n",
      "Epoch 22/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6947 - accuracy: 0.5065\n",
      "Epoch 22: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371/371 [==============================] - 1376s 4s/step - loss: 0.6947 - accuracy: 0.5065 - val_loss: 0.6955 - val_accuracy: 0.4892\n",
      "Epoch 23/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6941 - accuracy: 0.5065\n",
      "Epoch 23: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "371/371 [==============================] - 1373s 4s/step - loss: 0.6941 - accuracy: 0.5065 - val_loss: 0.6975 - val_accuracy: 0.4872\n",
      "Epoch 24/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6960 - accuracy: 0.5088\n",
      "Epoch 24: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "371/371 [==============================] - 1369s 4s/step - loss: 0.6960 - accuracy: 0.5088 - val_loss: 0.6923 - val_accuracy: 0.5034\n",
      "Epoch 25/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6957 - accuracy: 0.5073\n",
      "Epoch 25: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "371/371 [==============================] - 1371s 4s/step - loss: 0.6957 - accuracy: 0.5073 - val_loss: 0.6911 - val_accuracy: 0.4980\n",
      "Epoch 26/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.5057\n",
      "Epoch 26: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "371/371 [==============================] - 1374s 4s/step - loss: 0.6937 - accuracy: 0.5057 - val_loss: 0.7013 - val_accuracy: 0.4916\n",
      "Epoch 27/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6975 - accuracy: 0.5094\n",
      "Epoch 27: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "371/371 [==============================] - 1399s 4s/step - loss: 0.6975 - accuracy: 0.5094 - val_loss: 0.6941 - val_accuracy: 0.5230\n",
      "Epoch 28/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6962 - accuracy: 0.5065\n",
      "Epoch 28: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "371/371 [==============================] - 1395s 4s/step - loss: 0.6962 - accuracy: 0.5065 - val_loss: 0.7028 - val_accuracy: 0.5081\n",
      "Epoch 29/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6962 - accuracy: 0.5033\n",
      "Epoch 29: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "371/371 [==============================] - 1392s 4s/step - loss: 0.6962 - accuracy: 0.5033 - val_loss: 0.7068 - val_accuracy: 0.5068\n",
      "Epoch 30/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6952 - accuracy: 0.5026\n",
      "Epoch 30: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "371/371 [==============================] - 1395s 4s/step - loss: 0.6952 - accuracy: 0.5026 - val_loss: 0.6931 - val_accuracy: 0.5030\n",
      "Epoch 31/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6944 - accuracy: 0.5102\n",
      "Epoch 31: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "371/371 [==============================] - 1389s 4s/step - loss: 0.6944 - accuracy: 0.5102 - val_loss: 0.7068 - val_accuracy: 0.4905\n",
      "Epoch 32/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6962 - accuracy: 0.5084\n",
      "Epoch 32: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "371/371 [==============================] - 1393s 4s/step - loss: 0.6962 - accuracy: 0.5084 - val_loss: 0.6943 - val_accuracy: 0.4949\n",
      "Epoch 33/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6965 - accuracy: 0.5102\n",
      "Epoch 33: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "371/371 [==============================] - 1391s 4s/step - loss: 0.6965 - accuracy: 0.5102 - val_loss: 0.6974 - val_accuracy: 0.4983\n",
      "Epoch 34/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6960 - accuracy: 0.5108\n",
      "Epoch 34: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "371/371 [==============================] - 1383s 4s/step - loss: 0.6960 - accuracy: 0.5108 - val_loss: 0.6984 - val_accuracy: 0.5047\n",
      "Epoch 35/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6953 - accuracy: 0.5088\n",
      "Epoch 35: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "371/371 [==============================] - 1384s 4s/step - loss: 0.6953 - accuracy: 0.5088 - val_loss: 0.7040 - val_accuracy: 0.4916\n",
      "Model saved to /home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5\n",
      "Training end: 2024-03-15 15:53:07\n",
      "225/225 [==============================] - 249s 1s/step\n",
      "Overall Accuracy for test set:0.4975609756097561\n",
      "Prediction for period 4 successfully saved.\n"
     ]
    }
   ],
   "source": [
    "timesteps = 240\n",
    "num_input =1\n",
    "num_classes=1\n",
    "label = list(range(timesteps)) + ['target'] + ['ticker'] + ['target_date'] + ['sector']\n",
    "\n",
    "training_data = []\n",
    "training_label = []\n",
    "testing_data =[]\n",
    "testing_label =[]\n",
    "\n",
    "accuracy_results = []\n",
    "\n",
    "for i in range(5):\n",
    "    # read the data\n",
    "    path = '/home/RDC/yeungwin/H:/yeungwin/DAX/data/'\n",
    "    train = pd.read_csv(path+'Set_' + str(i) + '_Train.csv', index_col=0).dropna()\n",
    "    test = pd.read_csv(path+'Set_' + str(i) + '_Test.csv', index_col=0).dropna()\n",
    "\n",
    "    train.columns = label\n",
    "    test.columns = label\n",
    "\n",
    "    train_label = train.iloc[:, timesteps]\n",
    "    train_data = train.iloc[:, :timesteps]\n",
    "    test_label = test.iloc[:,timesteps]\n",
    "    test_data = test.iloc[:, :timesteps]\n",
    "    \n",
    "    \n",
    "     # reshape input\n",
    "    #  data: (samples, timesteps, features)\n",
    "    x_train = np.array(train_data).reshape((len(train_data), timesteps, num_input), order = 'F')\n",
    "    x_test = np.array(test_data).reshape((len(test_data), timesteps, num_input), order = 'F')\n",
    "    # label: (samples, target)\n",
    "    y_train = np.array(train_label).reshape((len(train_label), num_classes))\n",
    "    y_test = np.array(test_label).reshape((len(test_label), num_classes))\n",
    "        \n",
    "    print(x_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(x_test.shape)\n",
    "    print(y_test.shape)\n",
    "    \n",
    "    print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "    print(\"Training the model for Training Set \" + str(i) + \" from \" +\n",
    "    datetime.datetime.strftime(datetime.datetime.now(), '%Y-%m-%d %H:%M:%S'))\n",
    "    print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "        \n",
    "    if i==0:\n",
    "        tuner = keras_tuner.BayesianOptimization(build_model,\n",
    "            objective='val_accuracy',#overwrite=True,\n",
    "            max_trials=30, directory='tf', seed=666)\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience =10, restore_best_weights=False)\n",
    "        tuner.search(x_train,y_train, epochs =1000,validation_split=0.2, callbacks=[early_stop])\n",
    "\n",
    "        # save the best model\n",
    "        #hypermodel =build_model\n",
    "        best_hp = tuner.get_best_hyperparameters()[0]\n",
    "        best_model = build_model(best_hp)\n",
    "        print(tuner.get_best_hyperparameters()[0].get_config()[\"values\"])\n",
    "\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 10, restore_best_weights=False)\n",
    "        result = best_model.fit(x_train,y_train, epochs=1000, validation_split =0.2, verbose =1, callbacks=[early_stop])\n",
    "\n",
    "        \n",
    "    else:\n",
    "        load_path = '/home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5'\n",
    "        print('Model restore from ' + load_path)\n",
    "        cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=load_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                    patience = 10, restore_best_weights=False)\n",
    "\n",
    "        result = best_model.fit(\n",
    "            x_train, \n",
    "            y_train, \n",
    "            epochs = 1000, \n",
    "            validation_split=0.2,\n",
    "            verbose =1,\n",
    "            callbacks=[cp_callback, early_stop]        \n",
    "        ) \n",
    "        \n",
    "    save_path =  '/home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/transformer_model_weight/tf_weight.h5'\n",
    "    best_model.save_weights(save_path)\n",
    "    print(\"Model saved to \" + save_path)\n",
    "    print(\"Training end: \" + datetime.datetime.strftime(datetime.datetime.now(), '%Y-%m-%d %H:%M:%S'))\n",
    "        \n",
    "    ##make prediction\n",
    "    pred_ff_test = best_model.predict(x_test)\n",
    "    #pred = pred_ff_test.tolist()\n",
    "    pred = pred_ff_test.reshape((1, len(pred_ff_test))).tolist()[0]\n",
    "    output_data = pd.DataFrame({'y_prob': pred, 'y_true': test['target'], 'Ticker': test['ticker'],\n",
    "                                    'Date': test['target_date'], 'Sector': test['sector'], })\n",
    "    accuracy = accuracy_score(np.round(output_data['y_prob']), output_data['y_true'])\n",
    "    print('Overall Accuracy for test set:'+ str(accuracy))\n",
    "    \n",
    "    \n",
    "    output_data.to_csv('/home/RDC/yeungwin/H:/yeungwin/DAX/6_Transformer/tf_pred/tf_prediction_period_'+str(i)+'.csv')\n",
    "    print('Prediction for period ' + str(i) + ' successfully saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = keras_tuner.BayesianOptimization(MyHyperModel(),\n",
    "            objective='val_accuracy', #overwrite=True,\n",
    "            max_trials=30, directory='tf2', seed=666)\n",
    "\n",
    "print(tuner.get_best_hyperparameters()[0].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-tf]",
   "language": "python",
   "name": "conda-env-.conda-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
