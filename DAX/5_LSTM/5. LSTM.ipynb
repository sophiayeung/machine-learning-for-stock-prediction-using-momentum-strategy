{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2ebabd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, InputLayer, LSTM, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score\n",
    "import keras_tuner\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3dc231",
   "metadata": {},
   "source": [
    "# 240 days data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "477f5b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyHyperModel(keras_tuner.HyperModel):\n",
    "    def build(self,hp):\n",
    "        model = Sequential()\n",
    "        model.add(InputLayer(input_shape=(240,1 )))\n",
    "        hp_units = hp.Choice('units', values=[32,64,128])\n",
    "        hp_lr = hp.Choice('learning_rate', values=[1e-6,1e-7,1e-8])\n",
    "        hp_regulariers = hp.Choice('regularies', values = ['l1','l2', 'None'])\n",
    "        if hp_regulariers == 'l1':\n",
    "            regularizers = keras.regularizers.L1(hp_lr)\n",
    "        elif hp_regulariers == 'l2':\n",
    "            regularizers = keras.regularizers.L2(hp_lr)\n",
    "        elif hp_regulariers == 'None':\n",
    "            regularizers = None\n",
    "        \n",
    "        model.add(LSTM(units=hp_units,kernel_regularizer=regularizers,name='dense_0'))\n",
    "        model.add(Dropout(hp.Choice('dropout_rate',values =[0.5])))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        hp_optimizer = hp.Choice('optimizer', values=['sgd', 'rmsprop', 'adam',\"adamax\"])\n",
    "        if hp_optimizer == 'sgd':\n",
    "            optimizer = keras.optimizers.SGD(learning_rate=hp_lr)\n",
    "        elif hp_optimizer == 'rmsprop':\n",
    "            optimizer = keras.optimizers.RMSprop(learning_rate=hp_lr)\n",
    "        elif hp_optimizer == 'adam':\n",
    "            optimizer = keras.optimizers.Adam(learning_rate=hp_lr)\n",
    "        elif hp_optimizer == 'adamax':\n",
    "            optimizer = keras.optimizers.Adamax(learning_rate=hp_lr)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid optimizer choice\")\n",
    "\n",
    "        model.compile(\n",
    "            optimizer = optimizer\n",
    "            ,loss=keras.losses.BinaryCrossentropy()\n",
    "            , metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "\n",
    "    def fit(self, hp, model, *args, **kwargs):\n",
    "            return model.fit(\n",
    "                *args,\n",
    "                batch_size=hp.Choice(\"batch_size\", [16,32,64,128]),\n",
    "                **kwargs,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adaf0f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from lstm/untitled_project/tuner0.json\n",
      "Search space summary\n",
      "Default search space size: 6\n",
      "units (Choice)\n",
      "{'default': 32, 'conditions': [], 'values': [32, 64, 128], 'ordered': True}\n",
      "learning_rate (Choice)\n",
      "{'default': 1e-06, 'conditions': [], 'values': [1e-06, 1e-07, 1e-08], 'ordered': True}\n",
      "regularies (Choice)\n",
      "{'default': 'l1', 'conditions': [], 'values': ['l1', 'l2', 'None'], 'ordered': False}\n",
      "dropout_rate (Choice)\n",
      "{'default': 0.5, 'conditions': [], 'values': [0.5], 'ordered': True}\n",
      "optimizer (Choice)\n",
      "{'default': 'sgd', 'conditions': [], 'values': ['sgd', 'rmsprop', 'adam', 'adamax'], 'ordered': False}\n",
      "batch_size (Choice)\n",
      "{'default': 16, 'conditions': [], 'values': [16, 32, 64, 128], 'ordered': True}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "tuner = keras_tuner.BayesianOptimization(MyHyperModel(),\n",
    "            objective='val_accuracy', #overwrite=True,\n",
    "            max_trials=30, directory='lstm', seed=100)\n",
    "print(tuner.search_space_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71a70bd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14717, 240, 1)\n",
      "(14717, 1)\n",
      "(7149, 240, 1)\n",
      "(7149, 1)\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training the model for Training Set 0 from 2024-01-09 02:51:21\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Reloading Tuner from lstm/untitled_project/tuner0.json\n",
      "Epoch 1/1000\n",
      "368/368 [==============================] - 26s 67ms/step - loss: 0.6945 - accuracy: 0.4880 - val_loss: 0.6931 - val_accuracy: 0.5037\n",
      "Epoch 2/1000\n",
      "368/368 [==============================] - 23s 62ms/step - loss: 0.6937 - accuracy: 0.4939 - val_loss: 0.6931 - val_accuracy: 0.5037\n",
      "Epoch 3/1000\n",
      "368/368 [==============================] - 22s 59ms/step - loss: 0.6935 - accuracy: 0.4967 - val_loss: 0.6931 - val_accuracy: 0.5037\n",
      "Epoch 4/1000\n",
      "368/368 [==============================] - 21s 57ms/step - loss: 0.6936 - accuracy: 0.4963 - val_loss: 0.6931 - val_accuracy: 0.5034\n",
      "Epoch 5/1000\n",
      "368/368 [==============================] - 22s 59ms/step - loss: 0.6935 - accuracy: 0.5075 - val_loss: 0.6931 - val_accuracy: 0.5034\n",
      "Epoch 6/1000\n",
      "368/368 [==============================] - 21s 58ms/step - loss: 0.6937 - accuracy: 0.5035 - val_loss: 0.6931 - val_accuracy: 0.5034\n",
      "Epoch 7/1000\n",
      "368/368 [==============================] - 21s 58ms/step - loss: 0.6935 - accuracy: 0.5003 - val_loss: 0.6931 - val_accuracy: 0.5034\n",
      "Epoch 8/1000\n",
      "368/368 [==============================] - 21s 58ms/step - loss: 0.6934 - accuracy: 0.5028 - val_loss: 0.6931 - val_accuracy: 0.5034\n",
      "Epoch 9/1000\n",
      "368/368 [==============================] - 21s 58ms/step - loss: 0.6939 - accuracy: 0.4956 - val_loss: 0.6931 - val_accuracy: 0.5031\n",
      "Epoch 10/1000\n",
      "368/368 [==============================] - 21s 58ms/step - loss: 0.6935 - accuracy: 0.5007 - val_loss: 0.6931 - val_accuracy: 0.5031\n",
      "Epoch 11/1000\n",
      "368/368 [==============================] - 21s 58ms/step - loss: 0.6937 - accuracy: 0.4977 - val_loss: 0.6931 - val_accuracy: 0.5031\n",
      "{'units': 32, 'learning_rate': 1e-07, 'regularies': 'l1', 'dropout_rate': 0.5, 'optimizer': 'adamax', 'batch_size': 16}\n",
      "Model saved to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "Training end: 2024-01-09 02:55:27\n",
      "224/224 [==============================] - 4s 14ms/step\n",
      "Overall Accuracy for test set:0.5002098195551825\n",
      "Prediction for period 0 successfully saved.\n",
      "(14569, 240, 1)\n",
      "(14569, 1)\n",
      "(7500, 240, 1)\n",
      "(7500, 1)\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training the model for Training Set 1 from 2024-01-09 02:55:34\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model restore from /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "Epoch 1/1000\n",
      "364/365 [============================>.] - ETA: 0s - loss: 0.6937 - accuracy: 0.5036\n",
      "Epoch 1: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "365/365 [==============================] - 22s 60ms/step - loss: 0.6937 - accuracy: 0.5036 - val_loss: 0.6932 - val_accuracy: 0.4983\n",
      "Epoch 2/1000\n",
      "364/365 [============================>.] - ETA: 0s - loss: 0.6933 - accuracy: 0.5005\n",
      "Epoch 2: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "365/365 [==============================] - 22s 59ms/step - loss: 0.6933 - accuracy: 0.5006 - val_loss: 0.6932 - val_accuracy: 0.4983\n",
      "Epoch 3/1000\n",
      "365/365 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.5097\n",
      "Epoch 3: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "365/365 [==============================] - 21s 58ms/step - loss: 0.6931 - accuracy: 0.5097 - val_loss: 0.6932 - val_accuracy: 0.4983\n",
      "Epoch 4/1000\n",
      "365/365 [==============================] - ETA: 0s - loss: 0.6938 - accuracy: 0.4993\n",
      "Epoch 4: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "365/365 [==============================] - 21s 57ms/step - loss: 0.6938 - accuracy: 0.4993 - val_loss: 0.6932 - val_accuracy: 0.4983\n",
      "Epoch 5/1000\n",
      "364/365 [============================>.] - ETA: 0s - loss: 0.6933 - accuracy: 0.5003\n",
      "Epoch 5: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "365/365 [==============================] - 21s 59ms/step - loss: 0.6933 - accuracy: 0.5001 - val_loss: 0.6932 - val_accuracy: 0.4979\n",
      "Epoch 6/1000\n",
      "364/365 [============================>.] - ETA: 0s - loss: 0.6933 - accuracy: 0.5025\n",
      "Epoch 6: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "365/365 [==============================] - 21s 58ms/step - loss: 0.6933 - accuracy: 0.5024 - val_loss: 0.6932 - val_accuracy: 0.4979\n",
      "Epoch 7/1000\n",
      "365/365 [==============================] - ETA: 0s - loss: 0.6933 - accuracy: 0.5024\n",
      "Epoch 7: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "365/365 [==============================] - 21s 58ms/step - loss: 0.6933 - accuracy: 0.5024 - val_loss: 0.6932 - val_accuracy: 0.4976\n",
      "Epoch 8/1000\n",
      "364/365 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.5048\n",
      "Epoch 8: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "365/365 [==============================] - 21s 58ms/step - loss: 0.6932 - accuracy: 0.5049 - val_loss: 0.6932 - val_accuracy: 0.4976\n",
      "Epoch 9/1000\n",
      "364/365 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.5053\n",
      "Epoch 9: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "365/365 [==============================] - 21s 58ms/step - loss: 0.6932 - accuracy: 0.5054 - val_loss: 0.6932 - val_accuracy: 0.4976\n",
      "Epoch 10/1000\n",
      "365/365 [==============================] - ETA: 0s - loss: 0.6934 - accuracy: 0.4934\n",
      "Epoch 10: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "365/365 [==============================] - 21s 58ms/step - loss: 0.6934 - accuracy: 0.4934 - val_loss: 0.6932 - val_accuracy: 0.4976\n",
      "Epoch 11/1000\n",
      "364/365 [============================>.] - ETA: 0s - loss: 0.6936 - accuracy: 0.5043\n",
      "Epoch 11: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "365/365 [==============================] - 21s 58ms/step - loss: 0.6936 - accuracy: 0.5042 - val_loss: 0.6932 - val_accuracy: 0.4976\n",
      "Model saved to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "Training end: 2024-01-09 02:59:27\n",
      "235/235 [==============================] - 3s 14ms/step\n",
      "Overall Accuracy for test set:0.5054666666666666\n",
      "Prediction for period 1 successfully saved.\n",
      "(14919, 240, 1)\n",
      "(14919, 1)\n",
      "(7448, 240, 1)\n",
      "(7448, 1)\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training the model for Training Set 2 from 2024-01-09 02:59:34\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model restore from /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "Epoch 1/1000\n",
      "373/373 [==============================] - ETA: 0s - loss: 0.6936 - accuracy: 0.5020\n",
      "Epoch 1: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "373/373 [==============================] - 22s 59ms/step - loss: 0.6936 - accuracy: 0.5020 - val_loss: 0.6932 - val_accuracy: 0.4987\n",
      "Epoch 2/1000\n",
      "373/373 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.4992\n",
      "Epoch 2: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "373/373 [==============================] - 22s 58ms/step - loss: 0.6931 - accuracy: 0.4992 - val_loss: 0.6932 - val_accuracy: 0.4987\n",
      "Epoch 3/1000\n",
      "372/373 [============================>.] - ETA: 0s - loss: 0.6939 - accuracy: 0.4955\n",
      "Epoch 3: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "373/373 [==============================] - 22s 58ms/step - loss: 0.6938 - accuracy: 0.4958 - val_loss: 0.6932 - val_accuracy: 0.4987\n",
      "Epoch 4/1000\n",
      "373/373 [==============================] - ETA: 0s - loss: 0.6935 - accuracy: 0.5067\n",
      "Epoch 4: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "373/373 [==============================] - 21s 57ms/step - loss: 0.6935 - accuracy: 0.5067 - val_loss: 0.6932 - val_accuracy: 0.4987\n",
      "Epoch 5/1000\n",
      "373/373 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.5065\n",
      "Epoch 5: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "373/373 [==============================] - 22s 60ms/step - loss: 0.6932 - accuracy: 0.5065 - val_loss: 0.6932 - val_accuracy: 0.4987\n",
      "Epoch 6/1000\n",
      "373/373 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.4988\n",
      "Epoch 6: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "373/373 [==============================] - 22s 59ms/step - loss: 0.6937 - accuracy: 0.4988 - val_loss: 0.6932 - val_accuracy: 0.4987\n",
      "Epoch 7/1000\n",
      "373/373 [==============================] - ETA: 0s - loss: 0.6934 - accuracy: 0.5035\n",
      "Epoch 7: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "373/373 [==============================] - 22s 60ms/step - loss: 0.6934 - accuracy: 0.5035 - val_loss: 0.6932 - val_accuracy: 0.4987\n",
      "Epoch 8/1000\n",
      "373/373 [==============================] - ETA: 0s - loss: 0.6933 - accuracy: 0.5036\n",
      "Epoch 8: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "373/373 [==============================] - 24s 64ms/step - loss: 0.6933 - accuracy: 0.5036 - val_loss: 0.6932 - val_accuracy: 0.4987\n",
      "Epoch 9/1000\n",
      "373/373 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.5081\n",
      "Epoch 9: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "373/373 [==============================] - 24s 63ms/step - loss: 0.6932 - accuracy: 0.5081 - val_loss: 0.6932 - val_accuracy: 0.4987\n",
      "Epoch 10/1000\n",
      "373/373 [==============================] - ETA: 0s - loss: 0.6935 - accuracy: 0.4935\n",
      "Epoch 10: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "373/373 [==============================] - 22s 59ms/step - loss: 0.6935 - accuracy: 0.4935 - val_loss: 0.6932 - val_accuracy: 0.4987\n",
      "Epoch 11/1000\n",
      "373/373 [==============================] - ETA: 0s - loss: 0.6934 - accuracy: 0.5024\n",
      "Epoch 11: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "373/373 [==============================] - 24s 63ms/step - loss: 0.6934 - accuracy: 0.5024 - val_loss: 0.6932 - val_accuracy: 0.4987\n",
      "Epoch 12/1000\n",
      "373/373 [==============================] - ETA: 0s - loss: 0.6930 - accuracy: 0.5079\n",
      "Epoch 12: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "373/373 [==============================] - 23s 61ms/step - loss: 0.6930 - accuracy: 0.5079 - val_loss: 0.6932 - val_accuracy: 0.4987\n",
      "Epoch 13/1000\n",
      "373/373 [==============================] - ETA: 0s - loss: 0.6935 - accuracy: 0.5020\n",
      "Epoch 13: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "373/373 [==============================] - 23s 61ms/step - loss: 0.6935 - accuracy: 0.5020 - val_loss: 0.6932 - val_accuracy: 0.4987\n",
      "Epoch 14/1000\n",
      "373/373 [==============================] - ETA: 0s - loss: 0.6935 - accuracy: 0.5023\n",
      "Epoch 14: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "373/373 [==============================] - 22s 60ms/step - loss: 0.6935 - accuracy: 0.5023 - val_loss: 0.6932 - val_accuracy: 0.4987\n",
      "Model saved to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "Training end: 2024-01-09 03:04:48\n",
      "233/233 [==============================] - 3s 13ms/step\n",
      "Overall Accuracy for test set:0.5034908700322234\n",
      "Prediction for period 2 successfully saved.\n",
      "(15248, 240, 1)\n",
      "(15248, 1)\n",
      "(7058, 240, 1)\n",
      "(7058, 1)\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training the model for Training Set 3 from 2024-01-09 03:04:55\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model restore from /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "Epoch 1/1000\n",
      "381/382 [============================>.] - ETA: 0s - loss: 0.6939 - accuracy: 0.4998\n",
      "Epoch 1: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "382/382 [==============================] - 22s 58ms/step - loss: 0.6939 - accuracy: 0.5000 - val_loss: 0.6928 - val_accuracy: 0.5148\n",
      "Epoch 2/1000\n",
      "381/382 [============================>.] - ETA: 0s - loss: 0.6929 - accuracy: 0.5091\n",
      "Epoch 2: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "382/382 [==============================] - 22s 58ms/step - loss: 0.6929 - accuracy: 0.5089 - val_loss: 0.6928 - val_accuracy: 0.5148\n",
      "Epoch 3/1000\n",
      "381/382 [============================>.] - ETA: 0s - loss: 0.6937 - accuracy: 0.4934\n",
      "Epoch 3: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "382/382 [==============================] - 22s 59ms/step - loss: 0.6937 - accuracy: 0.4934 - val_loss: 0.6928 - val_accuracy: 0.5144\n",
      "Epoch 4/1000\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.5007\n",
      "Epoch 4: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "382/382 [==============================] - 23s 60ms/step - loss: 0.6937 - accuracy: 0.5007 - val_loss: 0.6928 - val_accuracy: 0.5144\n",
      "Epoch 5/1000\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.6934 - accuracy: 0.5085\n",
      "Epoch 5: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "382/382 [==============================] - 23s 60ms/step - loss: 0.6934 - accuracy: 0.5085 - val_loss: 0.6928 - val_accuracy: 0.5144\n",
      "Epoch 6/1000\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.6941 - accuracy: 0.4957\n",
      "Epoch 6: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "382/382 [==============================] - 23s 59ms/step - loss: 0.6941 - accuracy: 0.4957 - val_loss: 0.6928 - val_accuracy: 0.5144\n",
      "Epoch 7/1000\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.6938 - accuracy: 0.5015\n",
      "Epoch 7: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "382/382 [==============================] - 22s 58ms/step - loss: 0.6938 - accuracy: 0.5015 - val_loss: 0.6928 - val_accuracy: 0.5144\n",
      "Epoch 8/1000\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.6935 - accuracy: 0.5062\n",
      "Epoch 8: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "382/382 [==============================] - 22s 58ms/step - loss: 0.6935 - accuracy: 0.5062 - val_loss: 0.6928 - val_accuracy: 0.5144\n",
      "Epoch 9/1000\n",
      "381/382 [============================>.] - ETA: 0s - loss: 0.6935 - accuracy: 0.4986\n",
      "Epoch 9: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "382/382 [==============================] - 22s 58ms/step - loss: 0.6935 - accuracy: 0.4985 - val_loss: 0.6928 - val_accuracy: 0.5141\n",
      "Epoch 10/1000\n",
      "381/382 [============================>.] - ETA: 0s - loss: 0.6936 - accuracy: 0.5066\n",
      "Epoch 10: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "382/382 [==============================] - 22s 58ms/step - loss: 0.6936 - accuracy: 0.5064 - val_loss: 0.6928 - val_accuracy: 0.5141\n",
      "Epoch 11/1000\n",
      "381/382 [============================>.] - ETA: 0s - loss: 0.6936 - accuracy: 0.4958\n",
      "Epoch 11: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "382/382 [==============================] - 23s 60ms/step - loss: 0.6936 - accuracy: 0.4959 - val_loss: 0.6928 - val_accuracy: 0.5144\n",
      "Model saved to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "Training end: 2024-01-09 03:09:02\n",
      "221/221 [==============================] - 3s 15ms/step\n",
      "Overall Accuracy for test set:0.49702465287616887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for period 3 successfully saved.\n",
      "(14806, 240, 1)\n",
      "(14806, 1)\n",
      "(980, 240, 1)\n",
      "(980, 1)\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Training the model for Training Set 4 from 2024-01-09 03:09:08\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model restore from /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "Epoch 1/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6939 - accuracy: 0.5014\n",
      "Epoch 1: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "371/371 [==============================] - 23s 61ms/step - loss: 0.6939 - accuracy: 0.5014 - val_loss: 0.6931 - val_accuracy: 0.5098\n",
      "Epoch 2/1000\n",
      "370/371 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.5122\n",
      "Epoch 2: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "371/371 [==============================] - 22s 59ms/step - loss: 0.6932 - accuracy: 0.5124 - val_loss: 0.6931 - val_accuracy: 0.5098\n",
      "Epoch 3/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6934 - accuracy: 0.5035\n",
      "Epoch 3: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "371/371 [==============================] - 21s 57ms/step - loss: 0.6934 - accuracy: 0.5035 - val_loss: 0.6931 - val_accuracy: 0.5098\n",
      "Epoch 4/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6934 - accuracy: 0.5004\n",
      "Epoch 4: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "371/371 [==============================] - 22s 59ms/step - loss: 0.6934 - accuracy: 0.5004 - val_loss: 0.6931 - val_accuracy: 0.5098\n",
      "Epoch 5/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6939 - accuracy: 0.5014\n",
      "Epoch 5: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "371/371 [==============================] - 22s 60ms/step - loss: 0.6939 - accuracy: 0.5014 - val_loss: 0.6931 - val_accuracy: 0.5098\n",
      "Epoch 6/1000\n",
      "370/371 [============================>.] - ETA: 0s - loss: 0.6937 - accuracy: 0.4990\n",
      "Epoch 6: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "371/371 [==============================] - 22s 59ms/step - loss: 0.6937 - accuracy: 0.4990 - val_loss: 0.6931 - val_accuracy: 0.5098\n",
      "Epoch 7/1000\n",
      "370/371 [============================>.] - ETA: 0s - loss: 0.6935 - accuracy: 0.5043\n",
      "Epoch 7: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "371/371 [==============================] - 22s 59ms/step - loss: 0.6935 - accuracy: 0.5042 - val_loss: 0.6931 - val_accuracy: 0.5101\n",
      "Epoch 8/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6938 - accuracy: 0.5000\n",
      "Epoch 8: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "371/371 [==============================] - 23s 63ms/step - loss: 0.6938 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5101\n",
      "Epoch 9/1000\n",
      "370/371 [============================>.] - ETA: 0s - loss: 0.6946 - accuracy: 0.4927\n",
      "Epoch 9: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "371/371 [==============================] - 22s 60ms/step - loss: 0.6946 - accuracy: 0.4928 - val_loss: 0.6931 - val_accuracy: 0.5098\n",
      "Epoch 10/1000\n",
      "371/371 [==============================] - ETA: 0s - loss: 0.6935 - accuracy: 0.5054\n",
      "Epoch 10: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "371/371 [==============================] - 22s 59ms/step - loss: 0.6935 - accuracy: 0.5054 - val_loss: 0.6931 - val_accuracy: 0.5098\n",
      "Epoch 11/1000\n",
      "370/371 [============================>.] - ETA: 0s - loss: 0.6937 - accuracy: 0.5008\n",
      "Epoch 11: saving model to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "371/371 [==============================] - 21s 58ms/step - loss: 0.6937 - accuracy: 0.5008 - val_loss: 0.6931 - val_accuracy: 0.5098\n",
      "Model saved to /home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\n",
      "Training end: 2024-01-09 03:13:10\n",
      "31/31 [==============================] - 0s 13ms/step\n",
      "Overall Accuracy for test set:0.4897959183673469\n",
      "Prediction for period 4 successfully saved.\n"
     ]
    }
   ],
   "source": [
    "timesteps = 240\n",
    "num_input =1\n",
    "num_classes=1\n",
    "label = list(range(timesteps)) + ['target'] + ['ticker'] + ['target_date'] + ['sector']\n",
    "\n",
    "training_data = []\n",
    "training_label = []\n",
    "testing_data =[]\n",
    "testing_label =[]\n",
    "\n",
    "accuracy_results = []\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    # read the data\n",
    "    path  = '/home/RDC/yeungwin/H:/yeungwin/DAX/data/'\n",
    "    train = pd.read_csv(path+'Set_' + str(i) + '_Train.csv', index_col=0).dropna()\n",
    "    test = pd.read_csv(path+'Set_' + str(i) + '_Test.csv', index_col=0).dropna()\n",
    "\n",
    "    train.columns = label\n",
    "    test.columns = label\n",
    "\n",
    "    train_label = train.iloc[:, timesteps]\n",
    "    train_data = train.iloc[:, :timesteps]\n",
    "    test_label = test.iloc[:,timesteps]\n",
    "    test_data = test.iloc[:, :timesteps]\n",
    "    \n",
    "    \n",
    "     # reshape input\n",
    "    #  data: (samples, timesteps, features)\n",
    "    x_train = np.array(train_data).reshape((len(train_data), timesteps, num_input), order = 'F')\n",
    "    x_test = np.array(test_data).reshape((len(test_data), timesteps, num_input), order = 'F')\n",
    "    # label: (samples, target)\n",
    "    y_train = np.array(train_label).reshape((len(train_label), num_classes))\n",
    "    y_test = np.array(test_label).reshape((len(test_label), num_classes))\n",
    "        \n",
    "    print(x_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(x_test.shape)\n",
    "    print(y_test.shape)\n",
    "    \n",
    "    print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "    print(\"Training the model for Training Set \" + str(i) + \" from \" +\n",
    "    datetime.datetime.strftime(datetime.datetime.now(), '%Y-%m-%d %H:%M:%S'))\n",
    "    print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "        \n",
    "    if i ==0:   \n",
    "        tuner = keras_tuner.BayesianOptimization(MyHyperModel(),\n",
    "            objective='val_accuracy', #overwrite=True,\n",
    "            max_trials=30, directory='lstm', seed=100)\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience = 10, restore_best_weights=False)\n",
    "        tuner.search(x_train,y_train, epochs =1000, validation_split=0.2, callbacks=[early_stop])\n",
    "\n",
    "        # save the best model\n",
    "        hypermodel = MyHyperModel()\n",
    "        best_hp = tuner.get_best_hyperparameters()[0]\n",
    "        best_model = hypermodel.build(best_hp)\n",
    "\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience = 10, restore_best_weights=False)\n",
    "        result = best_model.fit(x_train,y_train, epochs=1000, validation_split =0.2, verbose =1, callbacks=[early_stop])\n",
    "        print(tuner.get_best_hyperparameters()[0].get_config()[\"values\"])\n",
    "\n",
    "    else: \n",
    "        load_path = '/home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5'\n",
    "        print('Model restore from ' + load_path)\n",
    "        cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=load_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                    patience = 10)\n",
    "\n",
    "        result = best_model.fit(\n",
    "            x_train, \n",
    "            y_train, \n",
    "            epochs = 1000, \n",
    "            validation_split=0.2,\n",
    "            verbose =1,\n",
    "            callbacks=[cp_callback, early_stop]        \n",
    "        ) \n",
    "            \n",
    "    model_path =\"/home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_model_weight/lstm_weight.h5\"    \n",
    "    best_model.save_weights(model_path)\n",
    "    print(\"Model saved to \" + model_path)\n",
    "    print(\"Training end: \" + datetime.datetime.strftime(datetime.datetime.now(), '%Y-%m-%d %H:%M:%S'))\n",
    "        \n",
    "    ##make prediction\n",
    "    pred_ff_test = best_model.predict(x_test)\n",
    "    #pred = pred_ff_test.tolist()\n",
    "    pred = pred_ff_test.reshape((1, len(pred_ff_test))).tolist()[0]\n",
    "    output_data = pd.DataFrame({'y_prob': pred, 'y_true': test['target'], 'Ticker': test['ticker'],\n",
    "                                    'Date': test['target_date'], 'Sector': test['sector'], })\n",
    "    accuracy = accuracy_score(np.round(output_data['y_prob']), output_data['y_true'])\n",
    "    print('Overall Accuracy for test set:'+ str(accuracy))\n",
    "    output_data.to_csv('/home/RDC/yeungwin/H:/yeungwin/DAX/5_LSTM/lstm_prediction/lstm_prediction_period_'+str(i)+'.csv')\n",
    "    print('Prediction for period ' + str(i) + ' successfully saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bf83bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from lstm/untitled_project/tuner0.json\n",
      "<keras_tuner.src.engine.hyperparameters.hyperparameters.HyperParameters object at 0x7f6262b0e290>\n"
     ]
    }
   ],
   "source": [
    "tuner = keras_tuner.BayesianOptimization(MyHyperModel(),\n",
    "            objective='val_accuracy', #overwrite=True,\n",
    "            max_trials=30, directory='lstm', seed=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a71266a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'units': 32, 'learning_rate': 1e-07, 'regularies': 'l1', 'dropout_rate': 0.5, 'optimizer': 'adamax', 'batch_size': 16}\n"
     ]
    }
   ],
   "source": [
    "print(tuner.get_best_hyperparameters()[0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7365d350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23303bbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-tf]",
   "language": "python",
   "name": "conda-env-.conda-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
