{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e0f620f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 21:12:06.891906: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-31 21:12:06.894509: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-31 21:12:06.940094: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-31 21:12:06.940131: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-31 21:12:06.940155: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-31 21:12:06.949415: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-31 21:12:06.949936: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-31 21:12:08.101402: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Dense,InputLayer, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import keras_tuner\n",
    "from keras.metrics import categorical_accuracy\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn import preprocessing\n",
    "import multiprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf4d8ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 05:32:00.331464: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.eager import context\n",
    "\n",
    "_ = tf.Variable([48])\n",
    "\n",
    "context._context = None\n",
    "context._create_context()\n",
    "\n",
    "tf.config.threading.set_inter_op_parallelism_threads(48)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2932e4a5",
   "metadata": {},
   "source": [
    "# Global Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e53ec8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyHyperModel(keras_tuner.HyperModel):\n",
    "    def build(self,hp):\n",
    "        model = Sequential()\n",
    "        model.add(InputLayer(input_shape=(240, ))) #240 timestamps with 1 feature\n",
    "        hp_units = hp.Choice('units', values=[32,64,128])\n",
    "        model.add(Dense(units=hp_units, name='dense_0'))\n",
    "        model.add(Dropout(hp.Choice('dropout_rate',values =[0.5])))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        hp_lr = hp.Choice('learning_rate', values=[1e-6, 1e-7, 1e-8])\n",
    "        hp_optimizer = hp.Choice('optimizer', values=['sgd', 'rmsprop', 'adam',\"adamax\"])\n",
    "        if hp_optimizer == 'sgd':\n",
    "            optimizer = keras.optimizers.SGD(learning_rate=hp_lr)\n",
    "        elif hp_optimizer == 'rmsprop':\n",
    "            optimizer = keras.optimizers.RMSprop(learning_rate=hp_lr)\n",
    "        elif hp_optimizer == 'adam':\n",
    "            optimizer = keras.optimizers.Adam(learning_rate=hp_lr)\n",
    "        elif hp_optimizer == 'adamax':\n",
    "            optimizer = keras.optimizers.Adamax(learning_rate=hp_lr)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid optimizer choice\")\n",
    "\n",
    "        model.compile(\n",
    "            optimizer = optimizer\n",
    "            ,loss=keras.losses.BinaryCrossentropy()\n",
    "            , metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "\n",
    "    def fit(self, hp, model, *args, **kwargs):\n",
    "            return model.fit(\n",
    "                *args,\n",
    "                batch_size=hp.Choice(\"batch_size\", [16,32, 64,128,256]),\n",
    "                **kwargs,\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6cb6133",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuner = keras_tuner.BayesianOptimization(MyHyperModel(),\n",
    "                objective='val_accuracy',  overwrite=True,\n",
    "                max_trials=30, directory='fnn', seed=11)\n",
    "print(tuner.search_space_siumm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed1fb77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "timesteps = 240\n",
    "num_input =1\n",
    "num_classes=1\n",
    "label = list(range(timesteps)) + ['target'] + ['ticker'] + ['target_date'] + ['sector']\n",
    "\n",
    "training_data = []\n",
    "training_label = []\n",
    "testing_data =[]\n",
    "testing_label =[]\n",
    "\n",
    "accuracy_results = []\n",
    "\n",
    "for i in range(5):\n",
    "    # read the data\n",
    "    data_path = '/DAX/data/'\n",
    "    train = pd.read_csv(data_path+'Set_' + str(i) + '_Train.csv', index_col=0).dropna()\n",
    "    test = pd.read_csv(data_path+'Set_' + str(i) + '_Test.csv', index_col=0).dropna()\n",
    "\n",
    "    train.columns = label\n",
    "    test.columns = label\n",
    "\n",
    "    train_label = train.iloc[:, timesteps]\n",
    "    train_data = train.iloc[:, :timesteps]\n",
    "    test_label = test.iloc[:,timesteps]\n",
    "    test_data = test.iloc[:, :timesteps]\n",
    "    \n",
    "    \n",
    "     # reshape input\n",
    "    #  data: (samples, timesteps, features)\n",
    "    x_train = np.array(train_data).reshape((len(train_data), timesteps, num_input), order = 'F')\n",
    "    x_test = np.array(test_data).reshape((len(test_data), timesteps, num_input), order = 'F')\n",
    "    # label: (samples, target)\n",
    "    y_train = np.array(train_label).reshape((len(train_label), num_classes))\n",
    "    y_test = np.array(test_label).reshape((len(test_label), num_classes))\n",
    "        \n",
    "    print(x_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(x_test.shape)\n",
    "    print(y_test.shape)\n",
    "    \n",
    "    print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "    print(\"Training the model for Training Set \" + str(i) + \" from \" +\n",
    "    datetime.datetime.strftime(datetime.datetime.now(), '%Y-%m-%d %H:%M:%S'))\n",
    "    print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "        \n",
    "        \n",
    "    if i==0:    \n",
    "        tuner = keras_tuner.BayesianOptimization(MyHyperModel(),\n",
    "                objective='val_accuracy',  #overwrite=True,\n",
    "                max_trials=30, directory='fnn', seed=11)\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 10, restore_best_weights=False)\n",
    "        tuner.search(x_train,y_train, epochs =1000,validation_split=0.2,callbacks=[early_stop])\n",
    "\n",
    "        # save the best model\n",
    "        hypermodel = MyHyperModel()\n",
    "        best_hp = tuner.get_best_hyperparameters()[0]\n",
    "        print(tuner.get_best_hyperparameters()[0].get_config()[\"values\"])\n",
    "        best_model = hypermodel.build(best_hp)\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 10, restore_best_weights=False)\n",
    "        result = best_model.fit(x_train,y_train, epochs=1000, validation_split =0.2, verbose =1, callbacks=[early_stop])\n",
    "\n",
    "\n",
    "    else:\n",
    "        load_path=\"n_weight.h5\"\n",
    "        print('Model restore from '+load_path)\n",
    "        cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=load_path,\n",
    "                                                     save_weights_only=True,\n",
    "                                                     verbose=1)\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                        patience = 10)\n",
    "        result = best_model.fit(\n",
    "                x_train, \n",
    "                y_train, \n",
    "                epochs = 1000, \n",
    "                validation_split=0.2,\n",
    "                verbose =1,\n",
    "                callbacks=[cp_callback, early_stop]        \n",
    "            )         \n",
    "      \n",
    "      \n",
    "        \n",
    "    save_path = \"/DAX/4_FNN/fnn_model_weight/fnn_weight.h5\"\n",
    "    best_model.save_weights(save_path)\n",
    "    print(\"Model saved to \" + save_path)\n",
    "    print(\"Training end: \" + datetime.datetime.strftime(datetime.datetime.now(), '%Y-%m-%d %H:%M:%S'))\n",
    "        \n",
    "    ##make prediction\n",
    "    pred_ff_test = best_model.predict(x_test)\n",
    "    #pred = pred_ff_test.tolist()\n",
    "    pred = pred_ff_test.reshape((1, len(pred_ff_test))).tolist()[0]\n",
    "    output_data = pd.DataFrame({'y_prob': pred, 'y_true': test['target'], 'Ticker': test['ticker'],\n",
    "                                    'Date': test['target_date'], 'Sector': test['sector'], })\n",
    "    accuracy = accuracy_score(np.round(output_data['y_prob']), output_data['y_true'])\n",
    "    print('Overall Accuracy for test set:'+ str(accuracy))\n",
    "    output_data.to_csv('prediction_period_'+str(i)+'.csv')\n",
    "    print('Prediction for period ' + str(i) + ' successfully saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e76dbdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb972399",
   "metadata": {},
   "source": [
    "# One model for each Sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b433975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Basic Materials', 'Consumer Cyclicals', 'Financials', 'Healthcare', 'Consumer Non-Cyclicals', 'Industrials', 'Technology', 'Real Estate', 'Utilities']\n"
     ]
    }
   ],
   "source": [
    "sector = pd.read_csv('/DAX/8_performance/stock_analysis.csv')\n",
    "sector_list = sector[\"Sector\"].unique().tolist()\n",
    "#sector_list.remove('Academic & Educational Services')\n",
    "print(sector_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc271360",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data_sector = pd.DataFrame()\n",
    "\n",
    "# Loop through the files and append their conten\n",
    "for sector in sector_list:\n",
    "    for i in range(23):  \n",
    "        path = 'fnn_'+sector+'_prediction_period_'+str(i)+'.csv'\n",
    "        data = pd.read_csv(path)  \n",
    "        # data = pd.read_csv('fnn_prediction_period_' + str(i) + '.csv')\n",
    "        combined_data_sector = pd.concat([combined_data_sector,data], ignore_index=True)\n",
    "\n",
    "# Save the combined data to a single CSV file\n",
    "combined_data_sector.to_csv('fnn_sector_prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "545515f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Healthcare': {0: 0.5088546578644032,\n",
       "  1: 0.50144030726555,\n",
       "  2: 0.5090358503467813,\n",
       "  3: 0.5078192458984937,\n",
       "  4: 0.504073680481757,\n",
       "  5: 0.5087660711304057,\n",
       "  6: 0.4978799185888738,\n",
       "  7: 0.49211006264372376,\n",
       "  8: 0.49651918316831684,\n",
       "  9: 0.4953172937187147,\n",
       "  10: 0.516927823333604,\n",
       "  11: 0.4990128331688055,\n",
       "  12: 0.504852033041944,\n",
       "  13: 0.4968835701819995,\n",
       "  14: 0.5011551155115511,\n",
       "  15: 0.5007905138339921,\n",
       "  16: 0.5012973137973138,\n",
       "  17: 0.504878426513861,\n",
       "  18: 0.5098808266706893,\n",
       "  19: 0.4929389029284971,\n",
       "  20: 0.5146420064452851,\n",
       "  21: 0.4962745232073279,\n",
       "  22: 0.5070559610705596},\n",
       " 'Financials': {0: 0.498618057383522,\n",
       "  1: 0.4904595373949322,\n",
       "  2: 0.5088226615520802,\n",
       "  3: 0.4895719620798621,\n",
       "  4: 0.4959862385321101,\n",
       "  5: 0.48956636005256243,\n",
       "  6: 0.5096995444541127,\n",
       "  7: 0.5089085725921401,\n",
       "  8: 0.4992282798108041,\n",
       "  9: 0.5079484479213681,\n",
       "  10: 0.5024968789013733,\n",
       "  11: 0.501265965228155,\n",
       "  12: 0.501370026209197,\n",
       "  13: 0.5041495014627739,\n",
       "  14: 0.4840451055662188,\n",
       "  15: 0.5046155752431696,\n",
       "  16: 0.4997070884592853,\n",
       "  17: 0.4806935094627207,\n",
       "  18: 0.5110081112398609,\n",
       "  19: 0.49335123385756297,\n",
       "  20: 0.4868379719796444,\n",
       "  21: 0.5262697022767076,\n",
       "  22: 0.5025267441097329},\n",
       " 'Industrials': {0: 0.5138282387190685,\n",
       "  1: 0.5121758067709364,\n",
       "  2: 0.4997244799559168,\n",
       "  3: 0.507515714676141,\n",
       "  4: 0.5136950904392765,\n",
       "  5: 0.5018045969733426,\n",
       "  6: 0.5035139279325326,\n",
       "  7: 0.49748979182006825,\n",
       "  8: 0.5089534962892354,\n",
       "  9: 0.4964308890330954,\n",
       "  10: 0.5028467153284671,\n",
       "  11: 0.5147146254458977,\n",
       "  12: 0.5006549265026925,\n",
       "  13: 0.5099610220874837,\n",
       "  14: 0.5050534428851887,\n",
       "  15: 0.49936143039591313,\n",
       "  16: 0.5140418502202643,\n",
       "  17: 0.4979526079076324,\n",
       "  18: 0.5060441020191286,\n",
       "  19: 0.49928459937565034,\n",
       "  20: 0.5019720101781171,\n",
       "  21: 0.5058520742692567,\n",
       "  22: 0.49945573294629897},\n",
       " 'Consumer Cyclicals': {0: 0.49296107890689694,\n",
       "  1: 0.5048429010158281,\n",
       "  2: 0.5096165191740413,\n",
       "  3: 0.5047448522829007,\n",
       "  4: 0.4981416957026713,\n",
       "  5: 0.5018028169014085,\n",
       "  6: 0.49828622801595773,\n",
       "  7: 0.506360302544121,\n",
       "  8: 0.49935339760169295,\n",
       "  9: 0.5017669858641131,\n",
       "  10: 0.5106702909027818,\n",
       "  11: 0.4908416137914522,\n",
       "  12: 0.49629368160960113,\n",
       "  13: 0.5009280742459397,\n",
       "  14: 0.5047375886524823,\n",
       "  15: 0.4981933647213402,\n",
       "  16: 0.5017388555169143,\n",
       "  17: 0.49397833207357017,\n",
       "  18: 0.4957437163149146,\n",
       "  19: 0.4967535661583866,\n",
       "  20: 0.49504900980196037,\n",
       "  21: 0.5024134743760912,\n",
       "  22: 0.49270726020712463},\n",
       " 'Technology': {0: 0.5008337224037884,\n",
       "  1: 0.5020957274202271,\n",
       "  2: 0.5007108698461936,\n",
       "  3: 0.4922676303342722,\n",
       "  4: 0.4966939473805891,\n",
       "  5: 0.4978562537457932,\n",
       "  6: 0.5002930171753144,\n",
       "  7: 0.5124206200971236,\n",
       "  8: 0.49619845988887806,\n",
       "  9: 0.5001275445130351,\n",
       "  10: 0.4995336076817558,\n",
       "  11: 0.4996488953708205,\n",
       "  12: 0.5018318908299262,\n",
       "  13: 0.5047184649260774,\n",
       "  14: 0.5001895067410255,\n",
       "  15: 0.5058136269168118,\n",
       "  16: 0.5027469173483091,\n",
       "  17: 0.5154385754541639,\n",
       "  18: 0.4926953332939019,\n",
       "  19: 0.5130317114784962,\n",
       "  20: 0.5104482738879029,\n",
       "  21: 0.501046601299989,\n",
       "  22: 0.49815195071868584},\n",
       " 'Consumer Non-Cyclicals': {0: 0.5121183774130453,\n",
       "  1: 0.5043291898842692,\n",
       "  2: 0.5066136422581482,\n",
       "  3: 0.5048725637181409,\n",
       "  4: 0.5157976352006203,\n",
       "  5: 0.4976298732707749,\n",
       "  6: 0.4870994399045083,\n",
       "  7: 0.5035226968697049,\n",
       "  8: 0.5072593654776841,\n",
       "  9: 0.5085484996510816,\n",
       "  10: 0.5025822000344293,\n",
       "  11: 0.48691236978026786,\n",
       "  12: 0.5064307364626853,\n",
       "  13: 0.4962057672338046,\n",
       "  14: 0.5142529488859764,\n",
       "  15: 0.5080950740613159,\n",
       "  16: 0.5058723404255319,\n",
       "  17: 0.5158694680375503,\n",
       "  18: 0.49957309553173324,\n",
       "  19: 0.5027577025484975,\n",
       "  20: 0.5058381159707105,\n",
       "  21: 0.5011030570438071,\n",
       "  22: 0.5034689862276069},\n",
       " 'Energy': {0: 0.48279082177161153,\n",
       "  1: 0.503494623655914,\n",
       "  2: 0.5028309104820199,\n",
       "  3: 0.504914004914005,\n",
       "  4: 0.5168963016678753,\n",
       "  5: 0.5152480655439236,\n",
       "  6: 0.50608,\n",
       "  7: 0.5299352750809061,\n",
       "  8: 0.48541033434650455,\n",
       "  9: 0.5321680376028202,\n",
       "  10: 0.516760124610592,\n",
       "  11: 0.5150486535415252,\n",
       "  12: 0.49223178668906153,\n",
       "  13: 0.4885272414838775,\n",
       "  14: 0.4908314737557,\n",
       "  15: 0.5097805124437506,\n",
       "  16: 0.4834804769272777,\n",
       "  17: 0.5004355822282451,\n",
       "  18: 0.48839882943143814,\n",
       "  19: 0.5024280469027597,\n",
       "  20: 0.49879453522635947,\n",
       "  21: 0.48747619745129633,\n",
       "  22: 0.4896465825938035},\n",
       " 'Utilities': {0: 0.49808156885036237,\n",
       "  1: 0.5072463768115942,\n",
       "  2: 0.49790081343479403,\n",
       "  3: 0.500133654103181,\n",
       "  4: 0.5165819414185427,\n",
       "  5: 0.5086280748990332,\n",
       "  6: 0.515,\n",
       "  7: 0.497375,\n",
       "  8: 0.5045800541865566,\n",
       "  9: 0.501786205001374,\n",
       "  10: 0.4980002758240243,\n",
       "  11: 0.4813294491525424,\n",
       "  12: 0.4894823025569971,\n",
       "  13: 0.48705179282868527,\n",
       "  14: 0.49244753375217215,\n",
       "  15: 0.46653333333333336,\n",
       "  16: 0.4750666666666667,\n",
       "  17: 0.5248,\n",
       "  18: 0.5400387919091161,\n",
       "  19: 0.5046570702794242,\n",
       "  20: 0.5102857142857142,\n",
       "  21: 0.49891414507021864,\n",
       "  22: 0.48516979509958447},\n",
       " 'Real Estate': {0: 0.524,\n",
       "  1: 0.513,\n",
       "  2: 0.501,\n",
       "  3: 0.5244988864142539,\n",
       "  4: 0.5182567726737338,\n",
       "  5: 0.5039370078740157,\n",
       "  6: 0.4977075904228222,\n",
       "  7: 0.5153922542204568,\n",
       "  8: 0.4914004914004914,\n",
       "  9: 0.5155038759689923,\n",
       "  10: 0.490625,\n",
       "  11: 0.5118238651807556,\n",
       "  12: 0.501317365269461,\n",
       "  13: 0.5134117647058823,\n",
       "  14: 0.5049075553526592,\n",
       "  15: 0.5006393861892583,\n",
       "  16: 0.48459498061620077,\n",
       "  17: 0.47960878390847017,\n",
       "  18: 0.5020519835841313,\n",
       "  19: 0.5099053814311059,\n",
       "  20: 0.5008438270803584,\n",
       "  21: 0.54,\n",
       "  22: 0.4973613077616167},\n",
       " 'Basic Materials': {0: 0.5086417671359919,\n",
       "  1: 0.504476802025866,\n",
       "  2: 0.49442603193733053,\n",
       "  3: 0.5037215160884003,\n",
       "  4: 0.507076425394258,\n",
       "  5: 0.5041496694331129,\n",
       "  6: 0.5051034482758621,\n",
       "  7: 0.4916678742211274,\n",
       "  8: 0.5048603610553927,\n",
       "  9: 0.4998349290194784,\n",
       "  10: 0.497289054557777,\n",
       "  11: 0.5002589331952356,\n",
       "  12: 0.49483729662077597,\n",
       "  13: 0.5093333333333333,\n",
       "  14: 0.49771622218947986,\n",
       "  15: 0.4925963934906905,\n",
       "  16: 0.5049666419570051,\n",
       "  17: 0.493358047574915,\n",
       "  18: 0.5045226130653266,\n",
       "  19: 0.5032691288213466,\n",
       "  20: 0.5121101237149329,\n",
       "  21: 0.5074782608695653,\n",
       "  22: 0.4892650054850337}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "554a925c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Healthcare', 'Financials', 'Industrials', 'Consumer Cyclicals', 'Technology', 'Consumer Non-Cyclicals', 'Energy', 'Utilities', 'Real Estate', 'Basic Materials']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cfcbff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dax_sector = pd.read_csv('/raw_data/dax_industry_all.csv')\n",
    "dax_sector_list = dax_sector[\"TRBC Economic Sector Name\"].unique()\n",
    "dax_sector_list = [x for x in dax_sector_list if pd.notnull(x)]\n",
    "print(dax_sector_list)\n",
    "\n",
    "timesteps = 240\n",
    "num_input =1\n",
    "num_classes=1\n",
    "label = list(range(timesteps)) + ['target'] + ['ticker'] + ['target_date'] + ['sector']\n",
    "\n",
    "training_data = []\n",
    "training_label = []\n",
    "testing_data =[]\n",
    "testing_label =[]\n",
    "\n",
    "accuracy_results = {}\n",
    "\n",
    "\n",
    "for sector in dax_sector_list:\n",
    "    accuracy_results[sector] = {}  # Create a sub-dictionary for each sector\n",
    "    for i in range(0,23):\n",
    "        # read the data\n",
    "        data_path = '/dax_data/'\n",
    "        train = pd.read_csv(data_path + 'Set_' + str(i) + '_Train.csv', index_col=0).dropna()\n",
    "        train = train[train['sector']==sector]\n",
    "        test = pd.read_csv(data_path + 'Set_' + str(i) + '_Test.csv', index_col=0).dropna()\n",
    "        test = test[test['sector']==sector]\n",
    "        \n",
    "        train.columns = label\n",
    "        test.columns = label\n",
    "\n",
    "        train_label = train.iloc[:, timesteps]\n",
    "        train_data = train.iloc[:, :timesteps]\n",
    "        test_label = test.iloc[:,timesteps]\n",
    "        test_data = test.iloc[:, :timesteps]\n",
    "\n",
    "\n",
    "         # reshape input\n",
    "        #  data: (samples, timesteps, features)\n",
    "        x_train = np.array(train_data).reshape((len(train_data), timesteps, num_input), order = 'F')\n",
    "        x_test = np.array(test_data).reshape((len(test_data), timesteps, num_input), order = 'F')\n",
    "        # label: (samples, target)\n",
    "        y_train = np.array(train_label).reshape((len(train_label), num_classes))\n",
    "        y_test = np.array(test_label).reshape((len(test_label), num_classes))\n",
    "\n",
    "        print(x_train.shape)\n",
    "        print(y_train.shape)\n",
    "        print(x_test.shape)\n",
    "        print(y_test.shape)\n",
    "\n",
    "        print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "        print(\"Training the model for Training Set \" + str(i) + \" from \" +\n",
    "        datetime.datetime.strftime(datetime.datetime.now(), '%Y-%m-%d %H:%M:%S'))\n",
    "        print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "        if i==0:    \n",
    "            tuner = keras_tuner.BayesianOptimization(MyHyperModel(),\n",
    "                    objective='val_accuracy',  overwrite=True,\n",
    "                    max_trials=30, directory='fnn'+sector, seed=11)\n",
    "            early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 10)\n",
    "            tuner.search(x_train,y_train, epochs =100,validation_split=0.2,callbacks=[early_stop])\n",
    "\n",
    "            # save the best model\n",
    "            hypermodel = MyHyperModel()\n",
    "            best_hp = tuner.get_best_hyperparameters()[0]\n",
    "            print(tuner.get_best_hyperparameters()[0].get_config()[\"values\"])\n",
    "            best_model = hypermodel.build(best_hp)\n",
    "            early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 10)\n",
    "            result = best_model.fit(x_train,y_train, epochs=1000, validation_split =0.2, verbose =1, callbacks=[early_stop])\n",
    "\n",
    "\n",
    "        else:\n",
    "            load_path=\"/DAX/4_FNN/fnn_model_weight/fnn_weight\"+sector+\"\".h5\"\n",
    "            print('Model restore from '+load_path)\n",
    "            cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=load_path,\n",
    "                                                         save_weights_only=True,\n",
    "                                                         verbose=1)\n",
    "            early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                            patience = 10)\n",
    "            result = best_model.fit(\n",
    "                    x_train, \n",
    "                    y_train, \n",
    "                    epochs = 1000, \n",
    "                    validation_split=0.2,\n",
    "                    verbose =1,\n",
    "                    callbacks=[cp_callback, early_stop]        \n",
    "                )         \n",
    "\n",
    "\n",
    "\n",
    "        save_path = '/DAX/4_FNN/fnn_model_weight/fnn_weight_'+sector+'.h5'\n",
    "        best_model.save_weights(save_path)\n",
    "        print(\"Model saved to \" + save_path)\n",
    "        print(\"Training end: \" + datetime.datetime.strftime(datetime.datetime.now(), '%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "        ##make prediction\n",
    "        pred_ff_test = best_model.predict(x_test)\n",
    "        pred = pred_ff_test.reshape((1, len(pred_ff_test))).tolist()[0]\n",
    "        output_data = pd.DataFrame({'y_prob': pred, 'y_true': test['target'], 'Ticker': test['ticker'],\n",
    "                                        'Date': test['target_date'], 'Sector': test['sector'], })\n",
    "        accuracy = accuracy_score(np.round(output_data['y_prob']), output_data['y_true'])\n",
    "        print('Overall Accuracy for test set:'+ str(accuracy))\n",
    "        accuracy_results[sector][i] = accuracy\n",
    "\n",
    "        output_data.to_csv('/DAX/4_FNN/fnn_prediction/fnn_'+sector + '_prediction_period_'+str(i)+'.csv')\n",
    "        print('Prediction for period ' +sector + str(i) + ' successfully saved.')\n",
    "        \n",
    "accuracy_df = pd.DataFrame(accuracy_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ba8e0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data_sector = pd.DataFrame()\n",
    "\n",
    "# Loop through the files and append their conten\n",
    "for sector in dax_sector_list:\n",
    "    for i in range(5):  \n",
    "        path = 'fnn_'+sector + '_prediction_period_'+str(i)+'.csv'\n",
    "        data = pd.read_csv(path)  \n",
    "        combined_data_sector = pd.concat([combined_data_sector,data], ignore_index=True)\n",
    "\n",
    "# Save the combined data to a single CSV file\n",
    "combined_data_sector.to_csv('dax_fnn_sector_prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e2194f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-tf]",
   "language": "python",
   "name": "conda-env-.conda-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
